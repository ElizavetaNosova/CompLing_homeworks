{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topicmodeling_gensim.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPK5R1mX7UY13OwOdGkPboN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElizavetaNosova/CompLing_homeworks/blob/master/Topicmodeling_gensim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4VgExSg79rs",
        "colab_type": "code",
        "outputId": "a0979538-3ef2-4558-b5ac-784ac360d5be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "source": [
        "!pip install gensim\n",
        "!pip install pandas\n",
        "!pip install nltk\n",
        "!pip install pymorphy2[fast]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.9.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.11.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.9 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.14.9)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.11.28)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->smart-open>=1.2.1->gensim) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Collecting pymorphy2[fast]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Collecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 25.3MB/s \n",
            "\u001b[?25hCollecting DAWG>=0.7.3; extra == \"fast\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c0/d8d967bcaa0b572f9dc1d878bbf5a7bfd5afa2102a5ae426731f6ce3bc26/DAWG-0.7.8.tar.gz (255kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 46.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: DAWG\n",
            "  Building wheel for DAWG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for DAWG: filename=DAWG-0.7.8-cp36-cp36m-linux_x86_64.whl size=775052 sha256=8218932c15f11c6866dcbb080d084dc64cf95142870b27dd485909bb167c9159\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/88/d0/4e4abc83eb8f59a71e8dbd8ba99fd5615a3af1fac1ef7f8825\n",
            "Successfully built DAWG\n",
            "Installing collected packages: dawg-python, pymorphy2-dicts, DAWG, pymorphy2\n",
            "Successfully installed DAWG-0.7.8 dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKf5HkSQ_dQu",
        "colab_type": "code",
        "outputId": "6eab08fe-e67f-486b-cf6c-1e36f87928d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "!pip install pyLDAvis"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.34.2)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.25.3)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.14.1)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.11.1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Collecting funcy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4b/6ffa76544e46614123de31574ad95758c421aae391a1764921b8a81e1eae/funcy-1.14.tar.gz (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 47.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.8.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (8.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.12.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (19.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (45.1.0)\n",
            "Building wheels for collected packages: pyLDAvis, funcy\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97711 sha256=55f552ab7090b01e59e6417f9d06ca364f31d30f547f84409265acb290241c96\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "  Building wheel for funcy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for funcy: filename=funcy-1.14-py2.py3-none-any.whl size=32042 sha256=e4508edc3ff8a676c3c5d436170b49947e2bd0773d45cfa43afa67db7f57a4b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/5a/d8/1d875df03deae6f178dfdf70238cca33f948ef8a6f5209f2eb\n",
            "Successfully built pyLDAvis funcy\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-1.14 pyLDAvis-2.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjmNkeOD8IJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import pyLDAvis.gensim\n",
        "import string\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "morph = MorphAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl_2dS8L_w8x",
        "colab_type": "code",
        "outputId": "113e0ab4-8c3c-4b19-ae93-a4d5f3498745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPBO7NV_BGi8",
        "colab_type": "text"
      },
      "source": [
        "При нормализации сразу не будем включать слова из списка стоп-слов и другие слова служебных частей речи, местоимения (видимо, местоимения-существительные, так как pymorphy только их выделяет отдельно) и числительные.\n",
        "Полагаю, ято в связи с этим список стопслов можно изначально урезать: скопировать из nltk и оставить только другие части речи, раз вышеупомянутые всё равно будут проверяться отдельно.\n",
        "Впрочем, непонятно, зачем я это делаю, если эти слова всё равно вряд ли станут \"ключевыми\" для тем"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNeb1bt8BFkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stops = ['как','так', 'было', 'еще', 'нет', 'теперь', 'когда', 'вдруг', 'уже', 'быть', 'был', 'нибудь', 'опять', 'там', 'потом', 'себя', 'ничего', 'может',  'тут', 'где', 'есть', 'надо', 'чем', 'была', 'сам', 'раз', 'тоже', 'себе', 'под', 'будет', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве',  'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n",
        "\n",
        "def remove_tags(text):\n",
        "    return re.sub(r'<[^>]+>', '', text)\n",
        "\n",
        "def opt_normalize(texts, n):\n",
        "    uniq = Counter()\n",
        "    for text in texts:\n",
        "        uniq.update(text)\n",
        "    \n",
        "    norm_uniq = {word:morph.parse(word)[0].normal_form for word, _ in uniq.most_common(n) if morph.parse(word)[0].tag.POS not in ['NUMR', 'NPRO', 'PREP', 'CONJ', 'PRCL', 'INTJ']}\n",
        "    \n",
        "    norm_texts = []\n",
        "    for text in texts:\n",
        "        \n",
        "        norm_words = [norm_uniq.get(word) for word in text]\n",
        "        norm_words = [word for word in norm_words if word and word not in stops]\n",
        "        norm_texts.append(norm_words)\n",
        "        \n",
        "    return norm_texts\n",
        "\n",
        "def tokenize(text):\n",
        "    words = [word.strip(string.punctuation) for word in text.split()]\n",
        "    words = [word for word in words if word]\n",
        "    \n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgNGWUxQJhLM",
        "colab_type": "code",
        "outputId": "3c0de7d5-fc56-4fad-a175-e4fb23bec376",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1b347ab9-bce4-4d04-946a-5542e0c73c0b\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-1b347ab9-bce4-4d04-946a-5542e0c73c0b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving habr_texts.txt to habr_texts (1).txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nvNzwT1MtPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = open('habr_texts.txt').read().splitlines()\n",
        "texts = opt_normalize([tokenize(remove_tags(text.lower())) for text in texts], 30000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwvgiaHAbU04",
        "colab_type": "code",
        "outputId": "919075d1-64c4-4e4e-e25e-de8668bbad7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(texts))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJVZcTfQOHCG",
        "colab_type": "text"
      },
      "source": [
        "Подберём параметры, при которых когерентность будет наибольшей. Для начала поберём параметры нграм и словаря при каких-нибудь параметрах модели. Будем надеяться, что при других параметрах модели они тоже хорошие"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYCDZR17N28x",
        "colab_type": "code",
        "outputId": "48c66efc-9b41-4e0f-a059-1389097bcfa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        }
      },
      "source": [
        "ngram_threshold_values = [0.2, 0.4, 0.6, 0.8]\n",
        "no_above_values = [0, 0.05, 0.1, 0.2, 0.25]\n",
        "no_below_values = [10, 20, 30, 50]\n",
        "best_res = 0\n",
        "best_params = {}\n",
        "for ngram_threshold in ngram_threshold_values:\n",
        "  for no_above in no_above_values:\n",
        "    for no_below in no_below_values:\n",
        "      try:\n",
        "        ph = gensim.models.Phrases(texts, scoring='npmi', threshold=ngram_threshold) # threshold можно подбирать\n",
        "        p = gensim.models.phrases.Phraser(ph)\n",
        "        ngrammed_texts = p[texts]\n",
        "        dictinary = gensim.corpora.Dictionary(texts)\n",
        "        dictinary.filter_extremes(no_above=no_above, no_below=no_below)\n",
        "        dictinary.compactify()\n",
        "        corpus = [dictinary.doc2bow(text) for text in texts]\n",
        "        lda = gensim.models.LdaMulticore(corpus, 100, id2word=dictinary, eval_every=0)\n",
        "        coherence_model_lda = gensim.models.CoherenceModel(model=lda, \n",
        "                                                    texts=texts, \n",
        "                                                     dictionary=dictinary, coherence='c_v')\n",
        "        if coherence_model_lda.get_coherence() > best_res:\n",
        "          best_res = coherence_model_lda.get_coherence()\n",
        "          best_params['ngram_threshold'] = ngram_threshold\n",
        "          best_params['no_above'] = no_above\n",
        "          best_params['no_below'] = no_below\n",
        "      except Exception as e:\n",
        "         print(e)\n",
        "print(best_params)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cannot compute LDA over an empty collection (no terms)\n",
            "cannot compute LDA over an empty collection (no terms)\n",
            "cannot compute LDA over an empty collection (no terms)\n",
            "cannot compute LDA over an empty collection (no terms)\n",
            "cannot compute LDA over an empty collection (no terms)\n",
            "cannot compute LDA over an empty collection (no terms)\n",
            "cannot compute LDA over an empty collection (no terms)\n",
            "cannot compute LDA over an empty collection (no terms)\n",
            "cannot compute LDA over an empty collection (no terms)\n",
            "cannot compute LDA over an empty collection (no terms)\n",
            "cannot compute LDA over an empty collection (no terms)\n",
            "cannot compute LDA over an empty collection (no terms)\n",
            "cannot compute LDA over an empty collection (no terms)\n",
            "cannot compute LDA over an empty collection (no terms)\n",
            "cannot compute LDA over an empty collection (no terms)\n",
            "cannot compute LDA over an empty collection (no terms)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-56:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\", line 333, in worker_e_step\n",
            "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py\", line 725, in do_estep\n",
            "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py\", line 679, in inference\n",
            "    phinorm = np.dot(expElogthetad, expElogbetad) + eps\n",
            "  File \"<__array_function__ internals>\", line 6, in dot\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-3620d71f2f70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdictinary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompactify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdictinary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMulticore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         coherence_model_lda = gensim.models.CoherenceModel(model=lda, \n\u001b[1;32m     19\u001b[0m                                                     \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;31m# wait for all outstanding jobs to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreallen\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \"\"\"\n\u001b[1;32m    267\u001b[0m                 \u001b[0mmerged_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m                     \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                     \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mempty\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSAV8LuV8Sn5",
        "colab_type": "text"
      },
      "source": [
        "Если честно, все варианты я не перебрала, но через какое-то время (часа полтора) лучшим результатом было {'ngram_threshold': 0.8, 'no_above': 0.05, 'no_below': 10}, когерентность 0.3816700738434562.\n",
        "Как минимум все предложенные характеристики нграм хотя бы по разу были опробованы, раз дело дошло до 0.8\n",
        " Промежуточные выводы: \n",
        "1. некоторые параметры отсекают весь корпус (отлавливалась соответствующая ошибка)\n",
        "2. не надо перебирать 80 сочетаний характеристик, если я хочу, чтобы процесс закончился через адекватное время"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1BzYV-l8-j8",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrKQcWXl8JaE",
        "colab_type": "code",
        "outputId": "9afe05a5-93d5-492c-e19c-54f3db022e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(best_params) \n",
        "print(best_res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ngram_threshold': 0.8, 'no_above': 0.05, 'no_below': 10}\n",
            "0.3816700738434562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mREoQ3m9Agp",
        "colab_type": "text"
      },
      "source": [
        "С учётом второго вывода  подберём настройки модели. Очень хочется верить, что, если корпус будет оформлен один раз, процесс будет хоть немного быстрее."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri848fkQ91ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ph = gensim.models.Phrases(texts, scoring='npmi', threshold=0.8) \n",
        "p = gensim.models.phrases.Phraser(ph)\n",
        "nrammed_texts = p[texts]\n",
        "dictinary = gensim.corpora.Dictionary(texts)\n",
        "dictinary.filter_extremes(no_above=0.05, no_below=10)\n",
        "dictinary.compactify()\n",
        "corpus = [dictinary.doc2bow(text) for text in texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwgU83Ca-g1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_topics = [50, 100, 200]\n",
        "n_eval = [0,1]\n",
        "best_res = 0\n",
        "best_params = {}\n",
        "best_topics = ''\n",
        "for n_topics in num_topics:\n",
        "  for n in n_eval:\n",
        "      lda = gensim.models.LdaMulticore(corpus, n_topics, id2word=dictinary, eval_every=n)\n",
        "      coherence_model_lda = gensim.models.CoherenceModel(model=lda, \n",
        "                                                texts=texts, \n",
        "                                                  dictionary=dictinary, coherence='c_v')\n",
        "      if coherence_model_lda.get_coherence() > best_res:\n",
        "        best_res = coherence_model_lda.get_coherence()\n",
        "        best_params['topics'] = n_topics\n",
        "        best_params[''] = n\n",
        "        best_model = lda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpXL9RWKNNAa",
        "colab_type": "code",
        "outputId": "91259202-b800-4b2f-ca68-3e2d96f8c337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        }
      },
      "source": [
        "best_model.print_topics()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(34,\n",
              "  '0.019*\"инцидент\" + 0.013*\"фоновый\" + 0.011*\"client\" + 0.010*\"chrome\" + 0.009*\"вкладка\" + 0.009*\"учётный\" + 0.008*\"бюджет\" + 0.007*\"иб\" + 0.007*\"долг\" + 0.006*\"select\"'),\n",
              " (80,\n",
              "  '0.034*\"twitter\" + 0.019*\"твит\" + 0.018*\"бот\" + 0.012*\"аккаунт\" + 0.008*\"выборка\" + 0.008*\"ботнет\" + 0.008*\"тестировщик\" + 0.007*\"общественный\" + 0.006*\"северный\" + 0.006*\"streaming\"'),\n",
              " (38,\n",
              "  '0.036*\"боль\" + 0.032*\"китай\" + 0.015*\"правительство\" + 0.015*\"атрибут\" + 0.015*\"vpn\" + 0.009*\"сопротивление\" + 0.008*\"•\" + 0.007*\"lt;/summary&gt\" + 0.007*\"чиновник\" + 0.007*\"англ\"'),\n",
              " (66,\n",
              "  '0.014*\"клетка\" + 0.009*\"атрибут\" + 0.007*\"математика\" + 0.007*\"женщина\" + 0.006*\"аудио\" + 0.006*\"образование\" + 0.006*\"ген\" + 0.005*\"хакер\" + 0.005*\"ит\" + 0.005*\"семья\"'),\n",
              " (98,\n",
              "  '0.026*\"foreach\" + 0.019*\"итерация\" + 0.018*\"do\" + 0.018*\"apply\" + 0.014*\"вектор\" + 0.013*\"fun\" + 0.009*\"матрица\" + 0.009*\"repeat\" + 0.008*\"result\" + 0.008*\"margin\"'),\n",
              " (61,\n",
              "  '0.040*\"домен\" + 0.012*\"переадресация\" + 0.012*\"миграция\" + 0.008*\"seo\" + 0.008*\"search\" + 0.007*\"console\" + 0.007*\"видимость\" + 0.006*\"перемещение\" + 0.006*\"бренд\" + 0.005*\"риска\"'),\n",
              " (40,\n",
              "  '0.020*\"up\" + 0.009*\"messages\" + 0.008*\"временный\" + 0.007*\"cookie\" + 0.007*\"php\" + 0.006*\"логин\" + 0.006*\"days\" + 0.005*\"use\" + 0.005*\"lt;div\" + 0.005*\"param\"'),\n",
              " (42,\n",
              "  '0.064*\"result\" + 0.026*\"let\" + 0.013*\"yahoo\" + 0.010*\"amount\" + 0.010*\"customer\" + 0.009*\"record\" + 0.008*\"case\" + 0.008*\"1.5\" + 0.007*\"amp;&amp\" + 0.007*\"get\"'),\n",
              " (51,\n",
              "  '0.014*\"клетка\" + 0.012*\"временный\" + 0.007*\"ген\" + 0.006*\"php\" + 0.005*\"виртуализация\" + 0.005*\"broadcast\" + 0.005*\"прерывание\" + 0.005*\"малый\" + 0.005*\"образование\" + 0.004*\"параллельный\"'),\n",
              " (24,\n",
              "  '0.013*\"атрибут\" + 0.011*\"прибор\" + 0.010*\"изделие\" + 0.009*\"стек\" + 0.008*\"статический\" + 0.007*\"площадь\" + 0.007*\"xiaomi\" + 0.006*\"mi\" + 0.005*\"линейка\" + 0.005*\"иконка\"'),\n",
              " (4,\n",
              "  '0.014*\"корея\" + 0.013*\"нативный\" + 0.012*\"кнут\" + 0.008*\"token\" + 0.006*\"южный\" + 0.006*\"веб\" + 0.006*\"бот\" + 0.005*\"инвестиция\" + 0.005*\"коммуникация\" + 0.005*\"lt;&lt\"'),\n",
              " (64,\n",
              "  '0.012*\"кэш\" + 0.011*\"at\" + 0.011*\"iaas\" + 0.011*\"client\" + 0.010*\"paas\" + 0.010*\"arm\" + 0.008*\"сброс\" + 0.008*\"select\" + 0.007*\"where\" + 0.007*\"state\"'),\n",
              " (1,\n",
              "  '0.020*\"яркость\" + 0.014*\"стикер\" + 0.014*\"репликация\" + 0.007*\"гаджет\" + 0.006*\"no\" + 0.006*\"more\" + 0.005*\"атрибут\" + 0.005*\"координата\" + 0.005*\"выделение\" + 0.005*\"цветок\"'),\n",
              " (70,\n",
              "  '0.012*\"админ\" + 0.011*\"домен\" + 0.009*\"users\" + 0.008*\"кожа\" + 0.008*\"state\" + 0.008*\"admin\" + 0.007*\"•\" + 0.007*\"off\" + 0.006*\"net\" + 0.006*\"add\"'),\n",
              " (71,\n",
              "  '0.017*\"стикер\" + 0.008*\"шифрование\" + 0.008*\"зашифровать\" + 0.008*\"выделение\" + 0.007*\"azure\" + 0.006*\"спецификация\" + 0.006*\"доска\" + 0.005*\"mi\" + 0.005*\"vpn\" + 0.005*\"uber\"'),\n",
              " (26,\n",
              "  '0.019*\"while\" + 0.015*\"iaas\" + 0.014*\"spi\" + 0.013*\"paas\" + 0.010*\"0x00\" + 0.007*\"байт\" + 0.006*\"define\" + 0.006*\"поезд\" + 0.005*\"робот\" + 0.005*\"регистр\"'),\n",
              " (33,\n",
              "  '0.007*\"студент\" + 0.004*\"redmine\" + 0.004*\"const\" + 0.004*\"вкладка\" + 0.004*\"trello\" + 0.004*\"key\" + 0.003*\"jira\" + 0.003*\"sum\" + 0.003*\"подсеть\" + 0.003*\"андрей\"'),\n",
              " (74,\n",
              "  '0.013*\"кампания\" + 0.009*\"бот\" + 0.008*\"adwords\" + 0.006*\"объявление\" + 0.006*\"спецификация\" + 0.006*\"скачивание\" + 0.004*\"предпочитать\" + 0.004*\"архив\" + 0.004*\"dvd\" + 0.004*\"dc\"'),\n",
              " (68,\n",
              "  '0.010*\"скидка\" + 0.008*\"токен\" + 0.006*\"char\" + 0.004*\"шлюз\" + 0.004*\"директива\" + 0.003*\"unsigned\" + 0.003*\"iot\" + 0.003*\"акция\" + 0.003*\"ssd\" + 0.003*\"хостинг\"'),\n",
              " (81,\n",
              "  '0.019*\"контейнер\" + 0.008*\"атрибут\" + 0.007*\"docker\" + 0.006*\"авторизация\" + 0.006*\"j\" + 0.006*\"run\" + 0.006*\"input\" + 0.005*\"rm\" + 0.005*\"messages\" + 0.005*\"your\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG-00QhrYR_d",
        "colab_type": "text"
      },
      "source": [
        "Лучшие темы:\n",
        "- ситуация в Китае (даже если убрать Китай, сочетание правительства и боли прекрасно)\n",
        "(38,\n",
        "  '0.036*\"боль\" + 0.032*\"китай\" + 0.015*\"правительство\" + 0.015*\"атрибут\" + 0.015*\"vpn\" + 0.009*\"сопротивление\" + 0.008*\"•\" + 0.007*\"lt;/summary&gt\" + 0.007*\"чиновник\" + 0.007*\"англ\"'),\n",
        "\n",
        "- экраны и графика:\n",
        " '0.020*\"яркость\" + 0.014*\"стикер\" + 0.014*\"репликация\" + 0.007*\"гаджет\" + 0.006*\"no\" + 0.006*\"more\" + 0.005*\"атрибут\" + 0.005*\"координата\" + 0.005*\"выделение\" + 0.005*\"цветок\"'),\n",
        "\n",
        " - биоинформатика\n",
        " 51,\n",
        "  '0.014*\"клетка\" + 0.012*\"временный\" + 0.007*\"ген\" + 0.006*\"php\" + 0.005*\"виртуализация\" + 0.005*\"broadcast\" + 0.005*\"прерывание\" + 0.005*\"малый\" + 0.005*\"образование\" + 0.004*\"параллельный\"'),\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7UVtQtEZQMb",
        "colab_type": "text"
      },
      "source": [
        "В выдачу попадало много слов типа \"user\" и команд языков программирования. В принципе, это не помешало, но перед следующим этапом лучше эти слова исключить. Добавим в предобработку ограничение: будем учитывать только слова, написанные кириллицей.\n",
        "Ещё попало имя \"Андрей\". В идеале стоило бы скопировать словарь имён и стереть оттуда имена известных чат-ботов и т.п., но будем надеяться, что корреляция имён с темами маловероятна."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEiW0XszrZzw",
        "colab_type": "code",
        "outputId": "06618fa0-b7d1-41fb-b2e6-285164164fab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "!wget https://github.com/mannefedov/compling_nlp_hse_course/raw/master/data/habr_texts.txt.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-06 12:04:08--  https://github.com/mannefedov/compling_nlp_hse_course/raw/master/data/habr_texts.txt.zip\n",
            "Resolving github.com (github.com)... 140.82.118.4\n",
            "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/habr_texts.txt.zip [following]\n",
            "--2020-02-06 12:04:08--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/habr_texts.txt.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18645068 (18M) [application/zip]\n",
            "Saving to: ‘habr_texts.txt.zip’\n",
            "\n",
            "habr_texts.txt.zip  100%[===================>]  17.78M  80.1MB/s    in 0.2s    \n",
            "\n",
            "2020-02-06 12:04:09 (80.1 MB/s) - ‘habr_texts.txt.zip’ saved [18645068/18645068]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mcsg1hyXrwXM",
        "colab_type": "code",
        "outputId": "659dbfad-1726-418e-ee40-3df24caff707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!unzip habr_texts.txt.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  habr_texts.txt.zip\n",
            "  inflating: habr_texts.txt          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97X3MTHFvFWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxz0e1DtvGSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbhKsQ_bbBmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = open('habr_texts.txt').read().splitlines()\n",
        "texts = [re.sub('[A-Za-z0-9]+', '', text) for text in texts]\n",
        "texts = [tokenize(remove_tags(text.lower())) for text in texts]\n",
        "texts = opt_normalize(texts, 3000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT0OgVhIBdDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN8Se9m3vK8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_ngrams(text):\n",
        "   ngrams = []\n",
        "   new_text = [word for word in text if len(word) > 1]\n",
        "   try: \n",
        "       for i in range(len(new_text)-1):\n",
        "         ngrams.append(new_text[i] + '+' + new_text[i+1])\n",
        "   except:\n",
        "       pass\n",
        "   return ngrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHsqDasSvL4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ngrammed_texts = [make_ngrams(text) for text in texts if make_ngrams(text)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pXRMc28CzzV",
        "colab_type": "code",
        "outputId": "167f1dbd-0162-4ca9-fbea-dbfe554d164d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(ngrammed_texts[5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['наш+литр', 'литр+число', 'число+метр', 'метр+наш', 'наш+год', 'год+год', 'год+наш', 'наш+метр', 'метр+наш', 'наш+наш', 'наш+литр', 'литр+плата', 'плата+далее', 'далее+наш', 'наш+наш', 'наш+наш', 'наш+плата', 'плата+далее', 'далее+литр', 'литр+литр', 'литр+наш', 'наш+плата', 'плата+литр', 'литр+наш', 'наш+плата', 'плата+литр', 'литр+наш', 'наш+наш', 'наш+наш', 'наш+наш', 'наш+плата', 'плата+метр', 'метр+литр', 'литр+далее', 'далее+наш', 'наш+плата', 'плата+наш', 'наш+литр', 'литр+метр', 'метр+плата', 'плата+метр', 'метр+наш', 'наш+наш', 'наш+наш', 'наш+плата', 'плата+литр', 'литр+наш', 'наш+наш', 'наш+метр', 'метр+плата', 'плата+метр', 'метр+далее', 'далее+наш', 'наш+наш', 'наш+наш', 'наш+плата', 'плата+литр', 'литр+метр', 'метр+наш', 'наш+наш', 'наш+число', 'число+литр', 'литр+метр', 'метр+литр', 'литр+наш', 'наш+наш', 'наш+метр', 'метр+метр', 'метр+число', 'число+метр', 'метр+наш', 'наш+плата', 'плата+наш', 'наш+наш', 'наш+наш', 'наш+метр', 'метр+литр', 'литр+наш', 'наш+плата', 'плата+метр', 'метр+плата', 'плата+далее', 'далее+плата', 'плата+число', 'число+наш', 'наш+плата', 'плата+метр', 'метр+метр', 'метр+год', 'год+далее', 'далее+наш', 'наш+число', 'число+год', 'год+наш', 'наш+число', 'число+плата', 'плата+плата', 'плата+метр', 'метр+литр', 'литр+литр', 'литр+далее', 'далее+литр', 'литр+наш', 'наш+плата', 'плата+далее', 'далее+литр', 'литр+наш', 'наш+наш', 'наш+метр', 'метр+наш', 'наш+литр', 'литр+плата', 'плата+метр', 'метр+плата', 'плата+далее', 'далее+далее', 'далее+плата', 'плата+наш', 'наш+метр', 'метр+наш', 'наш+плата', 'плата+метр', 'метр+наш', 'наш+год', 'год+далее', 'далее+наш', 'наш+плата', 'плата+метр', 'метр+наш', 'наш+далее', 'далее+наш', 'наш+год', 'год+литр', 'литр+число', 'число+наш', 'наш+год', 'год+далее', 'далее+литр', 'литр+метр', 'метр+наш', 'наш+год', 'год+плата', 'плата+далее', 'далее+литр', 'литр+год', 'год+плата', 'плата+далее', 'далее+наш', 'наш+год', 'год+далее', 'далее+плата', 'плата+далее', 'далее+наш', 'наш+литр', 'литр+число', 'число+плата', 'плата+наш', 'наш+число', 'число+плата', 'плата+далее', 'далее+литр', 'литр+год', 'год+далее', 'далее+плата', 'плата+наш', 'наш+год', 'год+литр', 'литр+наш', 'наш+наш', 'наш+наш', 'наш+наш', 'наш+литр', 'литр+наш', 'наш+год', 'год+плата', 'плата+далее', 'далее+метр', 'метр+плата', 'плата+далее', 'далее+далее', 'далее+число', 'число+далее', 'далее+плата', 'плата+наш', 'наш+год', 'год+далее', 'далее+число', 'число+наш', 'наш+литр', 'литр+далее', 'далее+год', 'год+плата', 'плата+литр', 'литр+наш', 'наш+далее', 'далее+литр', 'литр+литр', 'литр+наш', 'наш+наш', 'наш+метр', 'метр+литр', 'литр+далее', 'далее+метр', 'метр+год', 'год+метр', 'метр+плата', 'плата+наш', 'наш+наш', 'наш+метр', 'метр+год', 'год+литр', 'литр+наш', 'наш+метр', 'метр+литр', 'литр+литр', 'литр+число', 'число+год', 'год+плата', 'плата+литр', 'литр+наш', 'наш+далее', 'далее+число', 'число+литр', 'литр+число', 'число+плата', 'плата+литр', 'литр+число', 'число+литр', 'литр+плата', 'плата+метр', 'метр+плата', 'плата+литр', 'литр+плата', 'плата+число', 'число+наш', 'наш+плата', 'плата+метр', 'метр+плата', 'плата+далее', 'далее+литр', 'литр+литр', 'литр+литр', 'литр+число', 'число+плата', 'плата+далее', 'далее+литр', 'литр+плата', 'плата+литр', 'литр+литр', 'литр+наш', 'наш+литр', 'литр+наш', 'наш+наш', 'наш+метр', 'метр+плата', 'плата+плата', 'плата+далее', 'далее+литр', 'литр+год', 'год+далее', 'далее+литр', 'литр+литр', 'литр+плата', 'плата+плата', 'плата+год', 'год+год', 'год+плата', 'плата+далее', 'далее+наш', 'наш+литр', 'литр+метр', 'метр+метр', 'метр+плата', 'плата+наш', 'наш+метр', 'метр+плата', 'плата+плата', 'плата+далее', 'далее+метр', 'метр+плата', 'плата+наш', 'наш+далее', 'далее+наш', 'наш+литр', 'литр+год', 'год+литр', 'литр+наш', 'наш+плата', 'плата+число', 'число+метр', 'метр+наш', 'наш+литр', 'литр+далее', 'далее+литр', 'литр+наш', 'наш+метр', 'метр+наш', 'наш+метр', 'метр+литр', 'литр+наш', 'наш+наш', 'наш+плата', 'плата+литр', 'литр+наш', 'наш+далее', 'далее+литр', 'литр+наш', 'наш+метр', 'метр+плата', 'плата+далее', 'далее+метр', 'метр+далее', 'далее+плата', 'плата+литр', 'литр+наш', 'наш+литр', 'литр+наш', 'наш+наш', 'наш+метр', 'метр+метр', 'метр+наш', 'наш+литр', 'литр+число', 'число+литр', 'литр+наш', 'наш+плата', 'плата+литр', 'литр+плата', 'плата+литр', 'литр+литр', 'литр+наш', 'наш+плата', 'плата+литр', 'литр+литр', 'литр+наш', 'наш+плата', 'плата+литр', 'литр+метр', 'метр+литр', 'литр+плата', 'плата+далее', 'далее+год', 'год+литр', 'литр+год', 'год+далее', 'далее+число', 'число+плата', 'плата+число', 'число+метр', 'метр+наш', 'наш+метр', 'метр+литр', 'литр+наш', 'наш+метр', 'метр+метр', 'метр+плата', 'плата+далее', 'далее+литр', 'литр+метр', 'метр+плата', 'плата+литр', 'литр+число', 'число+наш', 'наш+число', 'число+литр', 'литр+наш', 'наш+литр', 'литр+наш', 'наш+плата', 'плата+литр', 'литр+наш', 'наш+год', 'год+плата', 'плата+плата', 'плата+метр', 'метр+плата', 'плата+наш', 'наш+литр', 'литр+наш', 'наш+далее', 'далее+наш', 'наш+наш', 'наш+плата', 'плата+плата', 'плата+плата', 'плата+далее', 'далее+плата', 'плата+число', 'число+плата', 'плата+литр', 'литр+наш', 'наш+наш', 'наш+литр', 'литр+плата', 'плата+число', 'число+литр', 'литр+далее', 'далее+наш', 'наш+число', 'число+плата', 'плата+далее', 'далее+метр', 'метр+плата', 'плата+метр', 'метр+плата', 'плата+плата', 'плата+наш', 'наш+число', 'число+литр', 'литр+плата', 'плата+далее', 'далее+литр', 'литр+метр', 'метр+метр', 'метр+литр', 'литр+далее', 'далее+число', 'число+наш', 'наш+плата', 'плата+метр', 'метр+плата', 'плата+литр', 'литр+наш', 'наш+метр', 'метр+число', 'число+плата', 'плата+далее', 'далее+литр', 'литр+год', 'год+плата', 'плата+метр', 'метр+плата', 'плата+далее', 'далее+наш', 'наш+число', 'число+литр', 'литр+плата', 'плата+далее', 'далее+год', 'год+плата', 'плата+метр', 'метр+плата', 'плата+наш', 'наш+литр', 'литр+число', 'число+наш', 'наш+метр', 'метр+плата', 'плата+литр', 'литр+метр', 'метр+метр', 'метр+литр', 'литр+плата', 'плата+метр', 'метр+наш', 'наш+наш', 'наш+далее', 'далее+плата', 'плата+литр', 'литр+литр', 'литр+наш', 'наш+метр', 'метр+далее', 'далее+наш', 'наш+плата', 'плата+литр', 'литр+литр', 'литр+наш', 'наш+метр', 'метр+далее', 'далее+плата', 'плата+наш', 'наш+плата', 'плата+метр', 'метр+далее', 'далее+плата', 'плата+наш', 'наш+наш', 'наш+далее', 'далее+литр', 'литр+метр', 'метр+наш', 'наш+год', 'год+далее', 'далее+метр', 'метр+метр', 'метр+далее', 'далее+литр', 'литр+наш', 'наш+наш', 'наш+литр', 'литр+метр', 'метр+литр', 'литр+число', 'число+далее', 'далее+метр', 'метр+метр', 'метр+плата', 'плата+метр', 'метр+литр', 'литр+наш', 'наш+наш', 'наш+наш', 'наш+наш', 'наш+литр', 'литр+плата', 'плата+метр', 'метр+наш', 'наш+плата', 'плата+литр', 'литр+литр', 'литр+плата', 'плата+метр', 'метр+год', 'год+далее', 'далее+литр', 'литр+литр', 'литр+плата', 'плата+метр', 'метр+наш', 'наш+наш', 'наш+плата', 'плата+далее', 'далее+литр', 'литр+литр', 'литр+литр', 'литр+наш', 'наш+наш', 'наш+наш', 'наш+плата', 'плата+метр', 'метр+метр', 'метр+плата', 'плата+плата', 'плата+плата', 'плата+метр', 'метр+плата', 'плата+далее', 'далее+наш', 'наш+литр', 'литр+метр', 'метр+литр', 'литр+год', 'год+метр', 'метр+плата', 'плата+наш', 'наш+метр', 'метр+плата', 'плата+наш', 'наш+наш', 'наш+плата', 'плата+метр', 'метр+наш', 'наш+литр', 'литр+наш', 'наш+наш', 'наш+число', 'число+наш', 'наш+далее', 'далее+плата', 'плата+плата', 'плата+далее', 'далее+литр', 'литр+год', 'год+плата', 'плата+литр', 'литр+наш', 'наш+далее', 'далее+год', 'год+число', 'число+наш', 'наш+литр', 'литр+плата', 'плата+литр', 'литр+метр', 'метр+литр', 'литр+год', 'год+далее', 'далее+год', 'год+далее', 'далее+число', 'число+наш', 'наш+метр', 'метр+далее', 'далее+литр', 'литр+литр', 'литр+плата', 'плата+метр', 'метр+плата', 'плата+литр', 'литр+число', 'число+литр', 'литр+год', 'год+плата', 'плата+метр', 'метр+метр', 'метр+плата', 'плата+далее', 'далее+литр', 'литр+плата', 'плата+далее', 'далее+литр', 'литр+наш', 'наш+наш', 'наш+метр', 'метр+плата', 'плата+далее', 'далее+наш', 'наш+число', 'число+плата', 'плата+литр', 'литр+плата', 'плата+далее', 'далее+плата', 'плата+наш', 'наш+метр', 'метр+литр', 'литр+далее', 'далее+метр', 'метр+наш', 'наш+число', 'число+наш', 'наш+наш', 'наш+число', 'число+наш', 'наш+наш', 'наш+плата', 'плата+метр', 'метр+плата', 'плата+плата', 'плата+плата', 'плата+литр', 'литр+литр', 'литр+литр', 'литр+наш', 'наш+наш', 'наш+наш', 'наш+далее', 'далее+литр', 'литр+литр', 'литр+число', 'число+наш', 'наш+плата', 'плата+далее', 'далее+число', 'число+наш', 'наш+метр', 'метр+метр', 'метр+метр', 'метр+литр', 'литр+плата', 'плата+литр', 'литр+литр', 'литр+наш', 'наш+плата', 'плата+число', 'число+далее', 'далее+литр', 'литр+литр', 'литр+наш', 'наш+плата', 'плата+литр', 'литр+наш', 'наш+наш', 'наш+плата', 'плата+литр', 'литр+число', 'число+литр', 'литр+плата', 'плата+метр', 'метр+число', 'число+метр', 'метр+наш', 'наш+метр', 'метр+наш', 'наш+наш', 'наш+литр', 'литр+наш', 'наш+наш', 'наш+наш', 'наш+наш', 'наш+литр', 'литр+метр', 'метр+плата', 'плата+литр', 'литр+метр', 'метр+число', 'число+наш', 'наш+наш', 'наш+метр', 'метр+далее', 'далее+литр', 'литр+наш', 'наш+плата', 'плата+число', 'число+далее', 'далее+литр', 'литр+далее', 'далее+плата', 'плата+литр', 'литр+наш', 'наш+наш', 'наш+метр', 'метр+наш', 'наш+год', 'год+литр', 'литр+год', 'год+наш', 'наш+наш', 'наш+год', 'год+год', 'год+литр', 'литр+наш', 'наш+наш', 'наш+метр', 'метр+наш', 'наш+далее', 'далее+литр', 'литр+наш', 'наш+наш', 'наш+метр', 'метр+плата', 'плата+плата', 'плата+число', 'число+наш', 'наш+год', 'год+литр', 'литр+наш', 'наш+метр', 'метр+далее', 'далее+литр', 'литр+наш', 'наш+наш', 'наш+плата', 'плата+метр', 'метр+число', 'число+метр', 'метр+литр', 'литр+далее', 'далее+наш', 'наш+наш', 'наш+плата', 'плата+литр', 'литр+метр', 'метр+наш', 'наш+наш', 'наш+метр', 'метр+метр', 'метр+далее', 'далее+литр', 'литр+наш', 'наш+наш', 'наш+далее', 'далее+метр', 'метр+литр', 'литр+наш', 'наш+год', 'год+число', 'число+литр', 'литр+плата', 'плата+наш', 'наш+плата', 'плата+литр', 'литр+число', 'число+литр', 'литр+метр', 'метр+плата', 'плата+литр', 'литр+далее', 'далее+литр', 'литр+наш', 'наш+наш', 'наш+наш', 'наш+литр', 'литр+далее', 'далее+плата', 'плата+далее', 'далее+литр', 'литр+литр', 'литр+наш', 'наш+плата', 'плата+наш', 'наш+литр', 'литр+далее', 'далее+год', 'год+плата', 'плата+наш', 'наш+число', 'число+метр', 'метр+наш', 'наш+литр', 'литр+далее', 'далее+число', 'число+метр', 'метр+метр', 'метр+плата', 'плата+далее', 'далее+литр', 'литр+наш', 'наш+число', 'число+далее', 'далее+литр', 'литр+литр', 'литр+далее', 'далее+наш', 'наш+далее', 'далее+наш', 'наш+далее', 'далее+наш', 'наш+далее', 'далее+плата', 'плата+плата', 'плата+число', 'число+наш', 'наш+плата', 'плата+далее', 'далее+литр', 'литр+далее', 'далее+литр', 'литр+далее', 'далее+год', 'год+плата', 'плата+плата', 'плата+литр', 'литр+наш', 'наш+плата', 'плата+литр', 'литр+наш', 'наш+метр', 'метр+наш', 'наш+год', 'год+метр', 'метр+наш', 'наш+число', 'число+плата', 'плата+литр', 'литр+метр', 'метр+наш', 'наш+литр', 'литр+плата', 'плата+далее', 'далее+наш', 'наш+метр', 'метр+плата', 'плата+наш', 'наш+наш', 'наш+плата', 'плата+метр', 'метр+далее', 'далее+наш', 'наш+далее', 'далее+литр', 'литр+наш', 'наш+год', 'год+плата', 'плата+плата', 'плата+метр', 'метр+плата', 'плата+плата', 'плата+литр', 'литр+литр', 'литр+наш', 'наш+далее', 'далее+метр', 'метр+плата', 'плата+наш', 'наш+метр', 'метр+плата', 'плата+литр', 'литр+число', 'число+литр', 'литр+плата', 'плата+наш', 'наш+метр', 'метр+литр', 'литр+наш', 'наш+наш', 'наш+плата', 'плата+метр', 'метр+наш', 'наш+плата', 'плата+метр', 'метр+плата', 'плата+плата', 'плата+далее', 'далее+наш', 'наш+плата', 'плата+далее', 'далее+наш', 'наш+литр', 'литр+число', 'число+литр', 'литр+наш', 'наш+литр', 'литр+далее', 'далее+наш', 'наш+число', 'число+плата', 'плата+метр', 'метр+наш', 'наш+наш', 'наш+метр', 'метр+наш', 'наш+литр', 'литр+наш', 'наш+год', 'год+литр', 'литр+год', 'год+плата', 'плата+плата', 'плата+метр', 'метр+литр', 'литр+плата', 'плата+метр', 'метр+наш', 'наш+литр', 'литр+наш', 'наш+далее', 'далее+число', 'число+наш', 'наш+плата', 'плата+литр', 'литр+литр', 'литр+метр', 'метр+далее', 'далее+наш', 'наш+число', 'число+наш', 'наш+метр', 'метр+далее', 'далее+литр', 'литр+число', 'число+наш', 'наш+наш', 'наш+плата', 'плата+литр', 'литр+литр', 'литр+метр', 'метр+далее', 'далее+наш', 'наш+наш', 'наш+число', 'число+метр', 'метр+метр', 'метр+наш', 'наш+далее', 'далее+литр', 'литр+наш', 'наш+плата', 'плата+литр', 'литр+наш', 'наш+далее', 'далее+литр', 'литр+число', 'число+литр', 'литр+литр', 'литр+далее', 'далее+плата', 'плата+наш', 'наш+число', 'число+литр', 'литр+далее', 'далее+метр', 'метр+наш', 'наш+наш', 'наш+год', 'год+число', 'число+наш', 'наш+метр', 'метр+метр', 'метр+год', 'год+далее', 'далее+наш', 'наш+наш', 'наш+число', 'число+число', 'число+метр', 'метр+литр', 'литр+наш', 'наш+литр', 'литр+метр', 'метр+плата', 'плата+далее', 'далее+наш', 'наш+литр', 'литр+наш', 'наш+год', 'год+плата', 'плата+наш', 'наш+год', 'год+метр', 'метр+наш', 'наш+год', 'год+литр', 'литр+плата', 'плата+число', 'число+литр', 'литр+далее', 'далее+число', 'число+наш', 'наш+плата', 'плата+наш', 'наш+плата', 'плата+далее', 'далее+литр', 'литр+метр', 'метр+плата', 'плата+наш', 'наш+наш', 'наш+наш', 'наш+наш', 'наш+наш', 'наш+число', 'число+литр', 'литр+год', 'год+далее', 'далее+плата', 'плата+далее', 'далее+плата', 'плата+число', 'число+плата', 'плата+метр', 'метр+наш', 'наш+число', 'число+наш', 'наш+число', 'число+плата', 'плата+литр', 'литр+наш', 'наш+год', 'год+метр', 'метр+метр', 'метр+наш', 'наш+наш', 'наш+далее', 'далее+литр', 'литр+наш', 'наш+год', 'год+число', 'число+год', 'год+метр', 'метр+метр', 'метр+плата', 'плата+далее', 'далее+литр', 'литр+число', 'число+год', 'год+наш', 'наш+наш', 'наш+наш', 'наш+метр', 'метр+наш', 'наш+литр', 'литр+число', 'число+число', 'число+наш', 'наш+наш', 'наш+метр', 'метр+плата', 'плата+наш', 'наш+наш', 'наш+год', 'год+наш', 'наш+наш', 'наш+наш', 'наш+плата', 'плата+далее', 'далее+плата', 'плата+число', 'число+метр', 'метр+наш', 'наш+плата', 'плата+наш', 'наш+наш', 'наш+плата', 'плата+метр', 'метр+метр', 'метр+наш', 'наш+метр', 'метр+число', 'число+наш', 'наш+далее', 'далее+литр', 'литр+наш', 'наш+наш', 'наш+плата', 'плата+плата', 'плата+далее', 'далее+число', 'число+метр', 'метр+наш', 'наш+далее', 'далее+метр', 'метр+плата', 'плата+наш', 'наш+плата', 'плата+литр', 'литр+метр', 'метр+литр', 'литр+наш', 'наш+литр', 'литр+наш', 'наш+плата', 'плата+метр', 'метр+далее', 'далее+литр', 'литр+наш', 'наш+плата', 'плата+далее', 'далее+литр', 'литр+наш', 'наш+плата', 'плата+литр', 'литр+метр', 'метр+плата', 'плата+далее', 'далее+наш', 'наш+плата', 'плата+метр', 'метр+далее', 'далее+наш', 'наш+плата', 'плата+плата', 'плата+литр', 'литр+метр', 'метр+наш', 'наш+наш', 'наш+плата', 'плата+метр', 'метр+литр', 'литр+литр', 'литр+год', 'год+наш', 'наш+год', 'год+наш', 'наш+плата', 'плата+метр', 'метр+далее', 'далее+плата', 'плата+литр', 'литр+метр', 'метр+литр', 'литр+наш', 'наш+наш', 'наш+метр', 'метр+далее', 'далее+плата', 'плата+далее', 'далее+метр', 'метр+наш', 'наш+литр', 'литр+наш', 'наш+плата', 'плата+литр', 'литр+число', 'число+метр', 'метр+далее', 'далее+наш', 'наш+метр', 'метр+метр', 'метр+метр', 'метр+наш', 'наш+год', 'год+метр', 'метр+наш', 'наш+плата', 'плата+наш', 'наш+метр', 'метр+литр', 'литр+год', 'год+плата', 'плата+плата', 'плата+литр', 'литр+наш', 'наш+наш', 'наш+далее', 'далее+метр', 'метр+далее', 'далее+литр', 'литр+далее', 'далее+литр', 'литр+наш', 'наш+наш', 'наш+метр', 'метр+плата', 'плата+метр', 'метр+плата', 'плата+литр', 'литр+наш', 'наш+литр', 'литр+наш', 'наш+число', 'число+метр', 'метр+плата', 'плата+наш', 'наш+число', 'число+наш', 'наш+число', 'число+литр', 'литр+метр', 'метр+наш', 'наш+число', 'число+год', 'год+литр', 'литр+наш', 'наш+метр', 'метр+наш', 'наш+плата', 'плата+литр', 'литр+литр', 'литр+литр', 'литр+число', 'число+плата', 'плата+далее', 'далее+далее', 'далее+плата', 'плата+плата', 'плата+наш', 'наш+наш', 'наш+метр', 'метр+метр', 'метр+год', 'год+плата', 'плата+плата', 'плата+наш', 'наш+год', 'год+далее', 'далее+плата', 'плата+далее', 'далее+плата', 'плата+число', 'число+плата', 'плата+число', 'число+наш', 'наш+плата', 'плата+метр', 'метр+далее', 'далее+плата', 'плата+литр', 'литр+наш', 'наш+литр', 'литр+литр', 'литр+плата', 'плата+плата', 'плата+литр', 'литр+наш', 'наш+год', 'год+плата', 'плата+далее', 'далее+число', 'число+далее', 'далее+литр', 'литр+плата', 'плата+литр', 'литр+наш', 'наш+литр', 'литр+год', 'год+наш', 'наш+наш', 'наш+наш', 'наш+плата', 'плата+далее', 'далее+литр', 'литр+наш', 'наш+наш', 'наш+метр', 'метр+наш', 'наш+плата', 'плата+число', 'число+метр', 'метр+плата', 'плата+метр', 'метр+число', 'число+литр', 'литр+плата', 'плата+далее', 'далее+далее', 'далее+метр', 'метр+наш', 'наш+далее', 'далее+наш', 'наш+плата', 'плата+метр', 'метр+год', 'год+литр', 'литр+метр', 'метр+плата', 'плата+далее', 'далее+литр', 'литр+метр', 'метр+метр', 'метр+литр', 'литр+далее', 'далее+наш', 'наш+далее', 'далее+плата', 'плата+плата', 'плата+плата', 'плата+литр', 'литр+литр', 'литр+число', 'число+метр', 'метр+метр', 'метр+литр', 'литр+наш', 'наш+наш', 'наш+число', 'число+литр', 'литр+метр', 'метр+наш', 'наш+литр', 'литр+число', 'число+плата', 'плата+плата', 'плата+метр', 'метр+плата', 'плата+метр', 'метр+метр', 'метр+наш', 'наш+плата', 'плата+литр', 'литр+плата', 'плата+литр', 'литр+наш', 'наш+метр', 'метр+метр', 'метр+наш', 'наш+плата', 'плата+метр', 'метр+литр', 'литр+метр', 'метр+плата', 'плата+наш', 'наш+плата', 'плата+далее', 'далее+литр', 'литр+наш', 'наш+литр', 'литр+наш', 'наш+плата', 'плата+литр', 'литр+наш', 'наш+число', 'число+литр', 'литр+литр', 'литр+плата', 'плата+далее', 'далее+наш', 'наш+наш', 'наш+наш', 'наш+плата', 'плата+метр', 'метр+год', 'год+далее', 'далее+литр', 'литр+год', 'год+число', 'число+литр', 'литр+метр', 'метр+наш', 'наш+год', 'год+литр', 'литр+наш', 'наш+далее', 'далее+литр', 'литр+литр', 'литр+наш', 'наш+наш', 'наш+литр', 'литр+метр', 'метр+литр', 'литр+метр', 'метр+наш', 'наш+метр', 'метр+метр', 'метр+далее', 'далее+наш', 'наш+год', 'год+далее', 'далее+наш', 'наш+метр', 'метр+наш', 'наш+наш', 'наш+наш', 'наш+год', 'год+плата', 'плата+плата', 'плата+метр', 'метр+плата', 'плата+наш', 'наш+литр', 'литр+метр', 'метр+наш', 'наш+год', 'год+далее', 'далее+наш', 'наш+далее', 'далее+наш', 'наш+число', 'число+наш', 'наш+плата', 'плата+литр', 'литр+наш', 'наш+литр', 'литр+число', 'число+наш', 'наш+далее', 'далее+литр', 'литр+наш', 'наш+наш', 'наш+литр', 'литр+наш', 'наш+наш', 'наш+метр', 'метр+наш', 'наш+метр', 'метр+плата', 'плата+наш', 'наш+плата', 'плата+литр', 'литр+литр', 'литр+литр', 'литр+число', 'число+наш', 'наш+плата', 'плата+литр', 'литр+метр', 'метр+метр', 'метр+наш', 'наш+литр', 'литр+число', 'число+плата', 'плата+литр', 'литр+метр', 'метр+литр', 'литр+метр', 'метр+далее', 'далее+литр', 'литр+наш', 'наш+плата', 'плата+наш', 'наш+литр', 'литр+наш', 'наш+плата', 'плата+плата', 'плата+литр', 'литр+наш', 'наш+литр', 'литр+далее', 'далее+далее', 'далее+метр', 'метр+год', 'год+литр', 'литр+далее', 'далее+наш', 'наш+плата', 'плата+год', 'год+наш', 'наш+наш', 'наш+метр', 'метр+далее', 'далее+литр', 'литр+метр', 'метр+наш', 'наш+метр', 'метр+метр', 'метр+число', 'число+наш', 'наш+далее', 'далее+далее', 'далее+литр', 'литр+плата', 'плата+наш', 'наш+наш', 'наш+метр', 'метр+метр', 'метр+наш', 'наш+метр', 'метр+плата', 'плата+метр', 'метр+год', 'год+литр', 'литр+число', 'число+плата', 'плата+далее', 'далее+год', 'год+далее', 'далее+наш', 'наш+плата', 'плата+год', 'год+плата', 'плата+литр', 'литр+литр', 'литр+метр', 'метр+наш', 'наш+метр', 'метр+наш', 'наш+наш', 'наш+плата', 'плата+литр', 'литр+наш', 'наш+метр', 'метр+наш', 'наш+наш', 'наш+метр', 'метр+плата', 'плата+число', 'число+метр', 'метр+наш', 'наш+плата', 'плата+литр', 'литр+метр', 'метр+наш', 'наш+далее', 'далее+наш', 'наш+наш', 'наш+наш', 'наш+метр', 'метр+наш', 'наш+год', 'год+плата', 'плата+далее', 'далее+далее', 'далее+число', 'число+далее', 'далее+наш', 'наш+литр', 'литр+наш', 'наш+литр', 'литр+литр', 'литр+наш', 'наш+плата', 'плата+литр', 'литр+литр', 'литр+число', 'число+плата', 'плата+литр', 'литр+число', 'число+наш', 'наш+метр', 'метр+наш', 'наш+литр', 'литр+наш', 'наш+число', 'число+далее', 'далее+плата', 'плата+далее', 'далее+плата', 'плата+плата', 'плата+далее', 'далее+год', 'год+метр', 'метр+плата', 'плата+число', 'число+наш', 'наш+метр', 'метр+наш', 'наш+плата', 'плата+литр', 'литр+литр', 'литр+наш', 'наш+литр', 'литр+наш', 'наш+наш', 'наш+плата', 'плата+метр', 'метр+год', 'год+далее', 'далее+наш', 'наш+наш', 'наш+метр', 'метр+наш', 'наш+далее', 'далее+литр', 'литр+наш', 'наш+литр', 'литр+наш', 'наш+литр', 'литр+плата', 'плата+метр', 'метр+наш', 'наш+число', 'число+наш', 'наш+плата', 'плата+метр', 'метр+плата', 'плата+литр', 'литр+число', 'число+литр', 'литр+плата', 'плата+литр', 'литр+литр', 'литр+метр', 'метр+наш', 'наш+метр', 'метр+плата', 'плата+далее', 'далее+литр', 'литр+метр', 'метр+наш', 'наш+наш', 'наш+метр', 'метр+далее', 'далее+плата', 'плата+метр', 'метр+плата', 'плата+далее', 'далее+наш', 'наш+метр', 'метр+плата', 'плата+наш', 'наш+плата', 'плата+литр', 'литр+литр', 'литр+метр', 'метр+число', 'число+метр', 'метр+плата', 'плата+наш', 'наш+наш', 'наш+наш', 'наш+наш', 'наш+литр', 'литр+число', 'число+наш', 'наш+метр', 'метр+наш', 'наш+плата', 'плата+литр', 'литр+литр', 'литр+год', 'год+наш', 'наш+год', 'год+метр', 'метр+плата', 'плата+число', 'число+литр', 'литр+литр', 'литр+плата', 'плата+литр', 'литр+далее', 'далее+литр', 'литр+наш', 'наш+метр', 'метр+наш', 'наш+метр', 'метр+наш', 'наш+метр', 'метр+далее', 'далее+литр', 'литр+наш', 'наш+литр', 'литр+год', 'год+далее', 'далее+наш', 'наш+год', 'год+метр', 'метр+наш', 'наш+наш', 'наш+год', 'год+далее', 'далее+плата', 'плата+далее', 'далее+год', 'год+литр', 'литр+далее', 'далее+наш', 'наш+наш', 'наш+наш', 'наш+метр', 'метр+наш', 'наш+наш', 'наш+метр', 'метр+наш', 'наш+наш', 'наш+наш', 'наш+плата', 'плата+далее', 'далее+плата', 'плата+наш', 'наш+литр', 'литр+число', 'число+метр', 'метр+литр', 'литр+литр', 'литр+год', 'год+литр', 'литр+наш', 'наш+литр', 'литр+литр', 'литр+далее', 'далее+плата', 'плата+далее', 'далее+плата', 'плата+литр', 'литр+число', 'число+литр', 'литр+плата', 'плата+плата', 'плата+литр', 'литр+число', 'число+литр', 'литр+наш', 'наш+далее', 'далее+литр', 'литр+литр', 'литр+наш', 'наш+метр', 'метр+наш', 'наш+наш', 'наш+метр', 'метр+наш', 'наш+наш', 'наш+далее', 'далее+метр', 'метр+метр', 'метр+наш', 'наш+далее', 'далее+плата', 'плата+наш', 'наш+литр', 'литр+число', 'число+плата', 'плата+далее', 'далее+плата', 'плата+наш', 'наш+наш', 'наш+литр', 'литр+плата', 'плата+наш', 'наш+метр', 'метр+литр', 'литр+число', 'число+плата', 'плата+далее', 'далее+далее', 'далее+наш', 'наш+метр', 'метр+метр', 'метр+наш', 'наш+год', 'год+наш', 'наш+далее', 'далее+метр', 'метр+наш', 'наш+наш', 'наш+метр', 'метр+наш', 'наш+наш', 'наш+число', 'число+наш', 'наш+метр', 'метр+плата', 'плата+далее', 'далее+плата', 'плата+число', 'число+плата', 'плата+далее', 'далее+далее', 'далее+метр', 'метр+год', 'год+метр', 'метр+литр', 'литр+далее', 'далее+число', 'число+далее', 'далее+литр', 'литр+наш', 'наш+наш', 'наш+плата', 'плата+наш', 'наш+плата', 'плата+литр', 'литр+наш', 'наш+метр', 'метр+далее', 'далее+литр', 'литр+год', 'год+далее', 'далее+число', 'число+наш', 'наш+плата', 'плата+литр', 'литр+наш', 'наш+наш', 'наш+литр', 'литр+плата', 'плата+наш', 'наш+плата', 'плата+далее', 'далее+метр', 'метр+число', 'число+наш', 'наш+наш', 'наш+год', 'год+метр', 'метр+плата', 'плата+литр', 'литр+литр', 'литр+метр', 'метр+наш', 'наш+наш', 'наш+год', 'год+плата', 'плата+литр', 'литр+наш', 'наш+литр', 'литр+плата', 'плата+литр', 'литр+далее', 'далее+наш', 'наш+наш', 'наш+метр', 'метр+плата', 'плата+наш', 'наш+метр', 'метр+плата', 'плата+далее', 'далее+литр', 'литр+литр', 'литр+плата', 'плата+литр', 'литр+наш', 'наш+плата', 'плата+далее', 'далее+метр', 'метр+литр', 'литр+далее', 'далее+метр', 'метр+метр', 'метр+плата', 'плата+литр', 'литр+наш', 'наш+метр', 'метр+далее', 'далее+метр', 'метр+плата', 'плата+далее', 'далее+плата', 'плата+число', 'число+плата', 'плата+далее', 'далее+литр', 'литр+литр', 'литр+литр', 'литр+число', 'число+год', 'год+далее', 'далее+литр', 'литр+число', 'число+плата', 'плата+литр', 'литр+число', 'число+число', 'число+литр', 'литр+плата', 'плата+далее', 'далее+метр', 'метр+метр', 'метр+плата', 'плата+метр', 'метр+метр', 'метр+наш', 'наш+наш', 'наш+плата', 'плата+литр', 'литр+наш', 'наш+наш', 'наш+далее', 'далее+год', 'год+литр', 'литр+наш', 'наш+далее', 'далее+плата', 'плата+литр', 'литр+наш', 'наш+литр', 'литр+наш', 'наш+метр', 'метр+литр', 'литр+число', 'число+литр', 'литр+метр', 'метр+наш', 'наш+наш', 'наш+наш', 'наш+метр', 'метр+наш', 'наш+наш', 'наш+метр', 'метр+плата', 'плата+метр', 'метр+плата', 'плата+далее', 'далее+наш', 'наш+число', 'число+литр', 'литр+литр', 'литр+далее', 'далее+плата', 'плата+метр', 'метр+число', 'число+год', 'год+плата', 'плата+литр', 'литр+плата', 'плата+далее', 'далее+литр', 'литр+год', 'год+плата', 'плата+наш', 'наш+плата', 'плата+литр', 'литр+наш', 'наш+метр', 'метр+плата', 'плата+далее', 'далее+плата', 'плата+литр', 'литр+наш', 'наш+метр', 'метр+наш', 'наш+год', 'год+метр', 'метр+наш', 'наш+наш', 'наш+плата', 'плата+плата', 'плата+далее', 'далее+плата', 'плата+число', 'число+число', 'число+метр', 'метр+наш', 'наш+литр', 'литр+число', 'число+далее', 'далее+литр', 'литр+год', 'год+метр', 'метр+наш', 'наш+плата', 'плата+число', 'число+литр', 'литр+наш', 'наш+плата', 'плата+метр', 'метр+метр', 'метр+наш', 'наш+плата', 'плата+литр', 'литр+метр', 'метр+наш', 'наш+литр', 'литр+наш', 'наш+плата', 'плата+литр', 'литр+наш', 'наш+литр', 'литр+число', 'число+наш', 'наш+метр', 'метр+наш', 'наш+число', 'число+наш', 'наш+наш', 'наш+плата', 'плата+далее', 'далее+число', 'число+наш', 'наш+плата', 'плата+метр', 'метр+литр', 'литр+литр', 'литр+далее', 'далее+плата', 'плата+наш', 'наш+наш', 'наш+число', 'число+метр', 'метр+плата', 'плата+плата', 'плата+плата', 'плата+плата', 'плата+далее', 'далее+наш', 'наш+наш', 'наш+литр', 'литр+год', 'год+метр', 'метр+наш', 'наш+год', 'год+литр', 'литр+плата', 'плата+метр', 'метр+наш', 'наш+наш', 'наш+метр', 'метр+наш', 'наш+плата', 'плата+плата', 'плата+далее', 'далее+далее', 'далее+плата', 'плата+далее', 'далее+плата', 'плата+литр', 'литр+наш', 'наш+число', 'число+метр', 'метр+метр', 'метр+наш', 'наш+плата', 'плата+число', 'число+наш', 'наш+метр', 'метр+литр', 'литр+год', 'год+наш', 'наш+метр', 'метр+литр', 'литр+число', 'число+наш', 'наш+литр', 'литр+литр', 'литр+далее', 'далее+наш', 'наш+литр', 'литр+далее', 'далее+литр', 'литр+плата', 'плата+литр', 'литр+плата', 'плата+метр', 'метр+литр', 'литр+плата', 'плата+плата', 'плата+метр', 'метр+наш', 'наш+плата', 'плата+число', 'число+наш', 'наш+плата', 'плата+число', 'число+метр', 'метр+литр', 'литр+наш']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYi2nzSBDnXF",
        "colab_type": "text"
      },
      "source": [
        "Не уверена, что с автором этой статьи всё в порядке, но теперь хотя бы в список входят слова, а не что попало"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKKe4hoOxlf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ph = gensim.models.Phrases(texts, scoring='npmi', threshold=0.8) \n",
        "p = gensim.models.phrases.Phraser(ph)\n",
        "nrammed_texts = p[texts]\n",
        "dictinary = gensim.corpora.Dictionary(ngrammed_texts)\n",
        "dictinary.filter_extremes(no_above=0.05, no_below=10)\n",
        "dictinary.compactify()\n",
        "corpus = [dictinary.doc2bow(text) for text in ngrammed_texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuRvFU1gdzGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_topics = [50, 100, 200]\n",
        "n_eval = [0,1]\n",
        "a = [0,1]\n",
        "best_res = 0\n",
        "best_params = {}\n",
        "for n_topics in num_topics:\n",
        "  for n in n_eval:\n",
        "    for alpha in a:\n",
        "      lda = gensim.models.LdaMulticore(corpus, n_topics, id2word=dictinary, eval_every=n, alpha=alpha)\n",
        "      coherence_model_lda = gensim.models.CoherenceModel(model=lda, \n",
        "                                                texts=texts, \n",
        "                                                  dictionary=dictinary, coherence='c_v')\n",
        "      if coherence_model_lda.get_coherence() > best_res:\n",
        "        best_res = coherence_model_lda.get_coherence()\n",
        "        best_model = lda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp71x0Qjsnhu",
        "colab_type": "code",
        "outputId": "9ed47a2e-76f4-40c7-d927-3efa5827c84e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "source": [
        "best_model.print_topics()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(80,\n",
              "  '0.002*\"выборка\" + 0.002*\"бот\" + 0.002*\"•\" + 0.002*\"вакансия\" + 0.002*\"студент\" + 0.002*\"инцидент\" + 0.002*\"атрибут\" + 0.002*\"преобразование\" + 0.002*\"координата\" + 0.002*\"боль\"'),\n",
              " (70,\n",
              "  '0.003*\"вакансия\" + 0.003*\"атрибут\" + 0.002*\"выборка\" + 0.002*\"домен\" + 0.002*\"студент\" + 0.002*\"метка\" + 0.002*\"•\" + 0.002*\"фильм\" + 0.002*\"кампания\" + 0.002*\"координата\"'),\n",
              " (37,\n",
              "  '0.004*\"боль\" + 0.004*\"•\" + 0.002*\"атрибут\" + 0.002*\"домен\" + 0.002*\"бот\" + 0.002*\"преобразование\" + 0.002*\"прибор\" + 0.002*\"выборка\" + 0.002*\"координата\" + 0.002*\"печать\"'),\n",
              " (75,\n",
              "  '0.005*\"атрибут\" + 0.003*\"•\" + 0.003*\"боль\" + 0.002*\"метаданные\" + 0.002*\"студент\" + 0.002*\"вакансия\" + 0.002*\"координата\" + 0.002*\"генератор\" + 0.002*\"репликация\" + 0.002*\"прибор\"'),\n",
              " (6,\n",
              "  '0.003*\"студент\" + 0.002*\"атрибут\" + 0.002*\"•\" + 0.002*\"вакансия\" + 0.002*\"инцидент\" + 0.002*\"боль\" + 0.002*\"кампания\" + 0.002*\"бот\" + 0.002*\"предприятие\" + 0.002*\"домен\"'),\n",
              " (29,\n",
              "  '0.002*\"студент\" + 0.002*\"•\" + 0.002*\"атрибут\" + 0.002*\"вакансия\" + 0.002*\"прибор\" + 0.002*\"датчик\" + 0.002*\"бот\" + 0.002*\"фич\" + 0.002*\"домен\" + 0.002*\"выборка\"'),\n",
              " (88,\n",
              "  '0.003*\"студент\" + 0.002*\"атрибут\" + 0.002*\"помещение\" + 0.002*\"домен\" + 0.002*\"яркость\" + 0.002*\"выборка\" + 0.002*\"бот\" + 0.002*\"вакансия\" + 0.002*\"•\" + 0.002*\"кампания\"'),\n",
              " (62,\n",
              "  '0.003*\"•\" + 0.002*\"боль\" + 0.002*\"студент\" + 0.002*\"выборка\" + 0.002*\"домен\" + 0.002*\"атрибут\" + 0.002*\"вакансия\" + 0.002*\"ценность\" + 0.002*\"объявление\" + 0.002*\"датчик\"'),\n",
              " (93,\n",
              "  '0.004*\"атрибут\" + 0.003*\"студент\" + 0.003*\"домен\" + 0.002*\"координата\" + 0.002*\"•\" + 0.002*\"предприятие\" + 0.002*\"вакансия\" + 0.002*\"печать\" + 0.002*\"боль\" + 0.002*\"дизайнер\"'),\n",
              " (9,\n",
              "  '0.003*\"студент\" + 0.002*\"бот\" + 0.002*\"боль\" + 0.002*\"домен\" + 0.002*\"•\" + 0.002*\"датчик\" + 0.002*\"прибор\" + 0.002*\"печать\" + 0.002*\"вакансия\" + 0.002*\"атрибут\"'),\n",
              " (56,\n",
              "  '0.005*\"боль\" + 0.003*\"атрибут\" + 0.003*\"•\" + 0.002*\"студент\" + 0.002*\"бот\" + 0.002*\"домен\" + 0.002*\"хост\" + 0.002*\"инцидент\" + 0.002*\"прибор\" + 0.002*\"вакансия\"'),\n",
              " (4,\n",
              "  '0.003*\"атрибут\" + 0.002*\"боль\" + 0.002*\"вакансия\" + 0.002*\"•\" + 0.002*\"студент\" + 0.002*\"бот\" + 0.002*\"домен\" + 0.002*\"робот\" + 0.002*\"выборка\" + 0.002*\"вычислительный\"'),\n",
              " (47,\n",
              "  '0.003*\"атрибут\" + 0.003*\"вакансия\" + 0.003*\"•\" + 0.002*\"хост\" + 0.002*\"кампания\" + 0.002*\"печать\" + 0.002*\"домен\" + 0.002*\"студент\" + 0.002*\"бот\" + 0.002*\"метаданные\"'),\n",
              " (19,\n",
              "  '0.008*\"•\" + 0.003*\"студент\" + 0.003*\"боль\" + 0.002*\"атрибут\" + 0.002*\"вакансия\" + 0.002*\"выборка\" + 0.002*\"помещение\" + 0.002*\"бот\" + 0.002*\"координата\" + 0.002*\"домен\"'),\n",
              " (83,\n",
              "  '0.003*\"•\" + 0.003*\"атрибут\" + 0.002*\"координата\" + 0.002*\"бот\" + 0.002*\"студент\" + 0.002*\"вакансия\" + 0.002*\"выражение\" + 0.002*\"домен\" + 0.002*\"выборка\" + 0.002*\"прибор\"'),\n",
              " (49,\n",
              "  '0.003*\"•\" + 0.002*\"атрибут\" + 0.002*\"кампания\" + 0.002*\"студент\" + 0.002*\"боль\" + 0.002*\"координата\" + 0.002*\"помещение\" + 0.002*\"репликация\" + 0.002*\"датчик\" + 0.002*\"бот\"'),\n",
              " (85,\n",
              "  '0.003*\"студент\" + 0.003*\"боль\" + 0.002*\"атрибут\" + 0.002*\"вакансия\" + 0.002*\"•\" + 0.002*\"помещение\" + 0.002*\"домен\" + 0.002*\"инцидент\" + 0.002*\"кампания\" + 0.002*\"выборка\"'),\n",
              " (63,\n",
              "  '0.003*\"атрибут\" + 0.003*\"боль\" + 0.002*\"•\" + 0.002*\"бот\" + 0.002*\"дизайнер\" + 0.002*\"вакансия\" + 0.002*\"вектор\" + 0.002*\"домен\" + 0.002*\"выборка\" + 0.002*\"координата\"'),\n",
              " (71,\n",
              "  '0.003*\"•\" + 0.003*\"студент\" + 0.003*\"боль\" + 0.003*\"атрибут\" + 0.002*\"кампания\" + 0.002*\"вакансия\" + 0.002*\"бот\" + 0.002*\"домен\" + 0.002*\"координата\" + 0.002*\"прибор\"'),\n",
              " (74,\n",
              "  '0.004*\"боль\" + 0.003*\"вакансия\" + 0.003*\"•\" + 0.002*\"выборка\" + 0.002*\"домен\" + 0.002*\"студент\" + 0.002*\"атрибут\" + 0.002*\"бот\" + 0.002*\"вектор\" + 0.002*\"прибор\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHURAx2q_iVS",
        "colab_type": "text"
      },
      "source": [
        "Ерунда какая-то: практически везде боль и студенты. Кажется, надо убрать точки из словаря и перезапустить подбор параметров для биграм. Кажется, также надо искусственным образом убрать студентов и вакансии, потому что студенты могут изучать что угодно и вакансии могут быть какие угодно. Вообще-то боль тоже стоит убрать, но очень хочется снова сгруппировать её с правительством."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgGjDCZjNbZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_stopwords_after_preprocessing(texts, new_stopwords):\n",
        "  new_texts = []\n",
        "  for text in texts:\n",
        "    new_text = []\n",
        "    for word in text:\n",
        "      if word not in new_stopwords:\n",
        "        new_text.append(word)\n",
        "    if new_text:\n",
        "      new_texts.append(new_text)\n",
        "  return new_texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t0FZXRwOMRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = add_stopwords_after_preprocessing(texts, ['.', 'студент', 'вакансия'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdjYS0H3O1Cn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Промежуточный вывод: идея перебирать 300 с лишним сочетаний параметров очень плохая. Пока что по первым 20 примерам наблюдается следующее: обычно с регуляризацией результат на несколько десятых лучше, \n",
        "# но выбиваются два набора параметров, с которыми когерентность раза в два больше обычной, причём оба без регуляризации"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSlQPSU8_R0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ph = gensim.models.Phrases(texts, scoring='npmi', threshold=0.8) \n",
        "p = gensim.models.phrases.Phraser(ph)\n",
        "ngrammed_texts = p[texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnHqKmxJD8Qe",
        "colab_type": "code",
        "outputId": "cabfd1b3-45eb-44c1-e0d0-d20eecbb2998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        }
      },
      "source": [
        "tr = [-1, -0, 1]\n",
        "no_above_values = [0.05, 0.15, 0.25]\n",
        "no_below_values = [10, 25, 50]\n",
        "num_topics = [50, 100, 200]\n",
        "n_eval = [0,1]\n",
        "a = [0,1]\n",
        "best_res = 0\n",
        "best_params = {}\n",
        "for no_above in no_above_values:\n",
        "  for no_below in no_below_values:\n",
        "    for t in tr:\n",
        "      for n in num_topics:\n",
        "        for n_ev in n_eval:\n",
        "          for alpha in a:\n",
        "            ph = gensim.models.Phrases(ngrammed_texts, scoring='npmi', threshold = t)\n",
        "            p = gensim.models.phrases.Phraser(ph)\n",
        "            ngrammed_texts = p[ngrammed_texts]\n",
        "            dictinary = gensim.corpora.Dictionary(ngrammed_texts)\n",
        "            dictinary.filter_extremes(no_above=no_above, no_below=no_below)\n",
        "            dictinary.compactify()\n",
        "            corpus = [dictinary.doc2bow(text) for text in texts]\n",
        "            lda = gensim.models.LdaMulticore(corpus, n, id2word=dictinary, eval_every=n_ev, alpha=alpha)\n",
        "            coherence_model_lda = gensim.models.CoherenceModel(model=lda, texts=ngrammed_texts, dictionary=dictinary, coherence='c_v')\n",
        "            params = [t, no_above, no_below, n, n_ev, alpha]\n",
        "            c = coherence_model_lda.get_coherence() \n",
        "            print('cogerence=', c, 'params:', params)\n",
        "            if c > best_res:\n",
        "              best_params_model = lda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cogerence= 0.3113832324845635 params: [-1, 0.05, 10, 50, 0, 0]\n",
            "cogerence= 0.37067050066018337 params: [-1, 0.05, 10, 50, 0, 1]\n",
            "cogerence= 0.3056127437967403 params: [-1, 0.05, 10, 50, 1, 0]\n",
            "cogerence= 0.3709433252914618 params: [-1, 0.05, 10, 50, 1, 1]\n",
            "cogerence= 0.3133048203514031 params: [-1, 0.05, 10, 100, 0, 0]\n",
            "cogerence= 0.3886867147612275 params: [-1, 0.05, 10, 100, 0, 1]\n",
            "cogerence= 0.30753516239835954 params: [-1, 0.05, 10, 100, 1, 0]\n",
            "cogerence= 0.3847320485348156 params: [-1, 0.05, 10, 100, 1, 1]\n",
            "cogerence= 0.6618007637492457 params: [-1, 0.05, 10, 200, 0, 0]\n",
            "cogerence= 0.3919988866546882 params: [-1, 0.05, 10, 200, 0, 1]\n",
            "cogerence= 0.6618007637492457 params: [-1, 0.05, 10, 200, 1, 0]\n",
            "cogerence= 0.3964581558850766 params: [-1, 0.05, 10, 200, 1, 1]\n",
            "cogerence= 0.32360493329650614 params: [0, 0.05, 10, 50, 0, 0]\n",
            "cogerence= 0.36355462406373285 params: [0, 0.05, 10, 50, 0, 1]\n",
            "cogerence= 0.3129983890656569 params: [0, 0.05, 10, 50, 1, 0]\n",
            "cogerence= 0.37137854092165135 params: [0, 0.05, 10, 50, 1, 1]\n",
            "cogerence= 0.3105739537377462 params: [0, 0.05, 10, 100, 0, 0]\n",
            "cogerence= 0.384274585453431 params: [0, 0.05, 10, 100, 0, 1]\n",
            "cogerence= 0.3190709164829746 params: [0, 0.05, 10, 100, 1, 0]\n",
            "cogerence= 0.3885441545139007 params: [0, 0.05, 10, 100, 1, 1]\n",
            "cogerence= 0.6618007637492457 params: [0, 0.05, 10, 200, 0, 0]\n",
            "cogerence= 0.3945483933813109 params: [0, 0.05, 10, 200, 0, 1]\n",
            "cogerence= 0.6618007637492457 params: [0, 0.05, 10, 200, 1, 0]\n",
            "cogerence= 0.3952690101983565 params: [0, 0.05, 10, 200, 1, 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-de833af5b7a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn_ev\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPhrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrammed_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'npmi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphrases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPhraser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mngrammed_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngrammed_texts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, min_count, threshold, max_vocab_size, delimiter, progress_per, scoring, common_terms)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36madd_vocab\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;31m# counts collected in previous learn_vocab runs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         min_reduce, vocab, total_words = self.learn_vocab(\n\u001b[0;32m--> 486\u001b[0;31m             sentences, self.max_vocab_size, self.delimiter, self.progress_per, self.common_terms)\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_word_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36mlearn_vocab\u001b[0;34m(sentences, max_vocab_size, delimiter, progress_per, common_terms)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mmin_reduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msentence_no\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprogress_per\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m                 logger.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0mnew_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_s\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0mnew_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_s\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36many2unicode\u001b[0;34m(text, encoding, errors)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00h_7BV1Qzg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#полный перебор не выполнился, возьмём один из лучших опробованных наборов параметров\n",
        "[t, no_above, no_below, n, n_ev, alpha] = [-1, 0.05, 10, 200, 1, 0]\n",
        "ph = gensim.models.Phrases(ngrammed_texts, scoring='npmi', threshold = t)\n",
        "p = gensim.models.phrases.Phraser(ph)\n",
        "ngrammed_texts = p[ngrammed_texts]\n",
        "dictinary = gensim.corpora.Dictionary(ngrammed_texts)\n",
        "dictinary.filter_extremes(no_above=no_above, no_below=no_below)\n",
        "dictinary.compactify()\n",
        "corpus = [dictinary.doc2bow(text) for text in texts]\n",
        "lda = gensim.models.LdaMulticore(corpus, n, id2word=dictinary, eval_every=n_ev, alpha=alpha)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGB26sAkQ22l",
        "colab_type": "code",
        "outputId": "dec4a818-0ccf-4553-ff34-1991479b78b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "source": [
        "lda.print_topics()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(172,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (42,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (188,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (136,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (2,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (30,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (191,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (169,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (76,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (62,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (107,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (189,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (20,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (59,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (71,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (193,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (11,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (174,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (86,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"'),\n",
              " (27,\n",
              "  'nan*\"медик\" + nan*\"масса_килограмм\" + nan*\"невольно\" + nan*\"находиться_прямо\" + nan*\"насквозь\" + nan*\"написать_очень\" + nan*\"молоток\" + nan*\"минь\" + nan*\"некоторый_модель\" + nan*\"материя\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N83Ob_fwu2u",
        "colab_type": "text"
      },
      "source": [
        "По-прежнему получаются одинаковые наборы слов. Наверно, нужно получать биграммы адекватным способом, а не склеивать в псевдослова"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vupfK4HsxFlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = open('habr_texts.txt').read().splitlines()\n",
        "texts = [re.sub('[A-Za-z0-9]+', '', text) for text in texts]\n",
        "texts = [tokenize(remove_tags(text.lower())) for text in texts]\n",
        "texts = opt_normalize(texts, 30000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHgV9Jjxxgza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ph = gensim.models.Phrases(texts, scoring='npmi', threshold=0.4)\n",
        "p = gensim.models.phrases.Phraser(ph)\n",
        "ngrammed_texts = p[texts]\n",
        "dictinary = gensim.corpora.Dictionary(ngrammed_texts)\n",
        "dictinary.filter_extremes(no_above=0.05, no_below=10)\n",
        "dictinary.compactify()\n",
        "corpus = [dictinary.doc2bow(text) for text in ngrammed_texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paFYuXjSzXvZ",
        "colab_type": "code",
        "outputId": "4ebb323f-9ed1-4a90-f033-83394932ad47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "best_res = 0\n",
        "for alpha in [0,1]:\n",
        "  for n_eval in [0, 1]:\n",
        "    lda = gensim.models.LdaMulticore(corpus, n, id2word=dictinary, eval_every=n_ev, alpha=alpha)\n",
        "    coherence_model_lda = gensim.models.CoherenceModel(model=lda, texts=ngrammed_texts, dictionary=dictinary, coherence='c_v')\n",
        "    if coherence_model_lda.get_coherence() > best_res:\n",
        "      best_model = lda\n",
        "      best_params = [alpha, n_eval]\n",
        "print(best_params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv1ElNl0wxne",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7f5vnNc19Nk",
        "colab_type": "code",
        "outputId": "8dd2454a-420a-4456-ccb1-496def8bdd1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "source": [
        "best_model.print_topics()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(25,\n",
              "  '0.008*\"кампания\" + 0.008*\"боль\" + 0.006*\"атрибут\" + 0.005*\"репликация\" + 0.004*\"усилитель\" + 0.004*\"координата\" + 0.003*\"младенец\" + 0.003*\"объявление\" + 0.003*\"•\" + 0.003*\"спецификация\"'),\n",
              " (148,\n",
              "  '0.009*\"боль\" + 0.007*\"атрибут\" + 0.004*\"кампания\" + 0.004*\"•\" + 0.004*\"объявление\" + 0.004*\"младенец\" + 0.004*\"репликация\" + 0.003*\"прибор\" + 0.003*\"усилитель\" + 0.003*\"сопротивление\"'),\n",
              " (20,\n",
              "  '0.009*\"боль\" + 0.007*\"кампания\" + 0.005*\"атрибут\" + 0.004*\"метаданные\" + 0.004*\"координата\" + 0.003*\"спецификация\" + 0.003*\"сопротивление\" + 0.003*\"объявление\" + 0.003*\"•\" + 0.003*\"усилитель\"'),\n",
              " (35,\n",
              "  '0.009*\"боль\" + 0.007*\"атрибут\" + 0.006*\"кампания\" + 0.005*\"репликация\" + 0.004*\"координата\" + 0.004*\"метаданные\" + 0.003*\"печать\" + 0.003*\"объявление\" + 0.003*\"усилитель\" + 0.003*\"головка\"'),\n",
              " (152,\n",
              "  '0.007*\"боль\" + 0.007*\"атрибут\" + 0.005*\"кампания\" + 0.004*\"усилитель\" + 0.004*\"печать\" + 0.004*\"головка\" + 0.004*\"координата\" + 0.003*\"метаданные\" + 0.003*\"объявление\" + 0.003*\"репликация\"'),\n",
              " (9,\n",
              "  '0.008*\"боль\" + 0.008*\"атрибут\" + 0.005*\"кампания\" + 0.004*\"метаданные\" + 0.004*\"печать\" + 0.003*\"головка\" + 0.003*\"координата\" + 0.003*\"сопротивление\" + 0.003*\"сериализация\" + 0.003*\"репликация\"'),\n",
              " (100,\n",
              "  '0.011*\"атрибут\" + 0.007*\"боль\" + 0.004*\"кампания\" + 0.004*\"метаданные\" + 0.003*\"фич\" + 0.003*\"стикер\" + 0.003*\"репликация\" + 0.003*\"словарь\" + 0.003*\"конструктор\" + 0.003*\"координата\"'),\n",
              " (182,\n",
              "  '0.006*\"кампания\" + 0.006*\"боль\" + 0.004*\"атрибут\" + 0.004*\"координата\" + 0.003*\"репликация\" + 0.003*\"печать\" + 0.003*\"головка\" + 0.003*\"объявление\" + 0.003*\"прибор\" + 0.003*\"робот\"'),\n",
              " (46,\n",
              "  '0.008*\"атрибут\" + 0.007*\"боль\" + 0.006*\"кампания\" + 0.004*\"метаданные\" + 0.004*\"объявление\" + 0.004*\"головка\" + 0.003*\"младенец\" + 0.003*\"усилитель\" + 0.003*\"репликация\" + 0.003*\"печать\"'),\n",
              " (60,\n",
              "  '0.007*\"атрибут\" + 0.005*\"боль\" + 0.005*\"прибор\" + 0.005*\"репликация\" + 0.004*\"печать\" + 0.004*\"кампания\" + 0.004*\"сериализация\" + 0.003*\"координата\" + 0.003*\"•\" + 0.003*\"спецификация\"'),\n",
              " (132,\n",
              "  '0.007*\"атрибут\" + 0.006*\"боль\" + 0.004*\"кампания\" + 0.004*\"головка\" + 0.004*\"•\" + 0.003*\"метаданные\" + 0.003*\"печать\" + 0.003*\"объявление\" + 0.003*\"сериализация\" + 0.003*\"координата\"'),\n",
              " (161,\n",
              "  '0.009*\"атрибут\" + 0.008*\"боль\" + 0.005*\"•\" + 0.004*\"стикер\" + 0.004*\"печать\" + 0.004*\"кампания\" + 0.003*\"прибор\" + 0.003*\"репликация\" + 0.003*\"метаданные\" + 0.003*\"головка\"'),\n",
              " (14,\n",
              "  '0.007*\"боль\" + 0.007*\"атрибут\" + 0.004*\"метаданные\" + 0.004*\"кампания\" + 0.004*\"прибор\" + 0.004*\"сопротивление\" + 0.004*\"координата\" + 0.004*\"головка\" + 0.003*\"конструктор\" + 0.003*\"репликация\"'),\n",
              " (184,\n",
              "  '0.009*\"боль\" + 0.007*\"атрибут\" + 0.005*\"кампания\" + 0.004*\"головка\" + 0.004*\"метаданные\" + 0.004*\"репликация\" + 0.003*\"•\" + 0.003*\"прибор\" + 0.003*\"координата\" + 0.003*\"стикер\"'),\n",
              " (165,\n",
              "  '0.008*\"атрибут\" + 0.008*\"боль\" + 0.005*\"кампания\" + 0.004*\"метаданные\" + 0.004*\"усилитель\" + 0.004*\"репликация\" + 0.004*\"печать\" + 0.004*\"координата\" + 0.004*\"сериализация\" + 0.004*\"стикер\"'),\n",
              " (82,\n",
              "  '0.009*\"боль\" + 0.006*\"атрибут\" + 0.004*\"кампания\" + 0.004*\"печать\" + 0.004*\"головка\" + 0.004*\"•\" + 0.004*\"прибор\" + 0.004*\"координата\" + 0.003*\"сопротивление\" + 0.003*\"репликация\"'),\n",
              " (57,\n",
              "  '0.007*\"боль\" + 0.007*\"атрибут\" + 0.006*\"кампания\" + 0.004*\"•\" + 0.004*\"прибор\" + 0.003*\"печать\" + 0.003*\"сериализация\" + 0.003*\"объявление\" + 0.003*\"младенец\" + 0.003*\"координата\"'),\n",
              " (29,\n",
              "  '0.009*\"боль\" + 0.006*\"атрибут\" + 0.005*\"кампания\" + 0.005*\"репликация\" + 0.004*\"метаданные\" + 0.003*\"•\" + 0.003*\"объявление\" + 0.003*\"младенец\" + 0.003*\"спецификация\" + 0.003*\"печать\"'),\n",
              " (55,\n",
              "  '0.007*\"боль\" + 0.005*\"атрибут\" + 0.005*\"кампания\" + 0.005*\"головка\" + 0.004*\"печать\" + 0.004*\"репликация\" + 0.004*\"прибор\" + 0.003*\"•\" + 0.003*\"младенец\" + 0.003*\"объявление\"'),\n",
              " (138,\n",
              "  '0.008*\"боль\" + 0.007*\"атрибут\" + 0.005*\"кампания\" + 0.004*\"репликация\" + 0.004*\"головка\" + 0.004*\"печать\" + 0.003*\"•\" + 0.003*\"координата\" + 0.003*\"младенец\" + 0.003*\"спецификация\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLMWQpG04b13",
        "colab_type": "text"
      },
      "source": [
        "Темы получились очень похожие и не особо интепретитуемые\n",
        "(25,\n",
        "  '0.008*\"кампания\" + 0.008*\"боль\" + 0.006*\"атрибут\" + 0.005*\"репликация\" + 0.004*\"усилитель\" + 0.004*\"координата\" + 0.003*\"младенец\" + 0.003*\"объявление\" + 0.003*\"•\" + 0.003*\"спецификация\"'),\n",
        " (148,\n",
        "  '0.009*\"боль\" + 0.007*\"атрибут\" + 0.004*\"кампания\" + 0.004*\"•\" + 0.004*\"объявление\" + 0.004*\"младенец\" + 0.004*\"репликация\" + 0.003*\"прибор\" + 0.003*\"усилитель\" + 0.003*\"сопротивление\"'),\n",
        " (20,\n",
        "  '0.009*\"боль\" + 0.007*\"кампания\" + 0.005*\"атрибут\" + 0.004*\"метаданные\" + 0.004*\"координата\" + 0.003*\"спецификация\" + 0.003*\"сопротивление\" + 0.003*\"объявление\" + 0.003*\"•\" + 0.003*\"усилитель\"'),\n",
        "  Предполагаю, что тексты хабра недостаточно разнообразны по тематике, чтобы через нграммы разграничивать разные значения одного слова"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD_6fB-zc2c6",
        "colab_type": "text"
      },
      "source": [
        "Добавим tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eorbB8Lge4nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ph = gensim.models.Phrases(texts, scoring='npmi', threshold=0.8) \n",
        "p = gensim.models.phrases.Phraser(ph)\n",
        "nrammed_texts = p[texts]\n",
        "dictionary = gensim.corpora.Dictionary(ngrammed_texts)\n",
        "dictionary.filter_extremes(no_above=0.05, no_below=10)\n",
        "dictionary.compactify()\n",
        "corpus = [dictionary.doc2bow(text) for text in ngrammed_texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TPGj6uBgPFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf = gensim.models.TfidfModel(corpus, id2word=dictionary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEVOTDRJd0sQ",
        "colab_type": "code",
        "outputId": "dc3f147b-d54b-4dce-cf0f-4ad83d33e927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "n_eval = [0,1]\n",
        "alpha = [0,1,2]\n",
        "best_res = 0\n",
        "for n in n_eval:\n",
        "  for a in alpha:\n",
        "    lda = gensim.models.LdaMulticore(corpus=tfidf[corpus], id2word=dictionary, eval_every=n)\n",
        "    coherence_model_lda = gensim.models.CoherenceModel(model=lda, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "    c = coherence_model_lda.get_coherence() \n",
        "    print('Когерентность:', c, 'параметры:', [n, a])\n",
        "    if c > best_res:\n",
        "      best_model = lda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Когерентность: nan параметры: [0, 0]\n",
            "Когерентность: nan параметры: [0, 1]\n",
            "Когерентность: nan параметры: [0, 2]\n",
            "Когерентность: nan параметры: [1, 0]\n",
            "Когерентность: nan параметры: [1, 1]\n",
            "Когерентность: nan параметры: [1, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdXBIA13drE3",
        "colab_type": "text"
      },
      "source": [
        "По метрикам все модели не очень, посмотрим н последнюю"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKNL7CNagiZ_",
        "colab_type": "code",
        "outputId": "63330c60-d7c5-41e4-e46b-9c3b3274277e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        }
      },
      "source": [
        "lda.print_topics()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3,\n",
              "  '0.123*\"датчик\" + 0.091*\"станция\" + 0.045*\"переходить\" + 0.024*\"авторизация\" + 0.024*\"кластер\" + 0.023*\"убедиться\" + 0.023*\"софт\" + 0.022*\"обслуживание\" + 0.022*\"отсутствовать\" + 0.022*\"корректно\"'),\n",
              " (40,\n",
              "  '0.034*\"дерево\" + 0.021*\"субд\" + 0.020*\"датчик\" + 0.019*\"полый\" + 0.017*\"шифрование\" + 0.017*\"тело\" + 0.015*\"граница\" + 0.015*\"клетка\" + 0.014*\"ося\" + 0.011*\"оперативный\"'),\n",
              " (60,\n",
              "  '0.084*\"клетка\" + 0.044*\"курс\" + 0.026*\"рейтинг\" + 0.025*\"баг\" + 0.024*\"штука\" + 0.024*\"ценность\" + 0.024*\"внезапно\" + 0.023*\"тело\" + 0.023*\"рассказывать\" + 0.023*\"пк\"'),\n",
              " (5,\n",
              "  '0.036*\"плагин\" + 0.028*\"слой\" + 0.021*\"доклад\" + 0.021*\"бд\" + 0.012*\"кат\" + 0.011*\"ия\" + 0.009*\"угол\" + 0.009*\"допустить\" + 0.009*\"аппарат\" + 0.009*\"«как\"'),\n",
              " (76,\n",
              "  '0.022*\"спутник\" + 0.018*\"“_”\" + 0.014*\"регистрация\" + 0.014*\"желательно\" + 0.014*\"отображение\" + 0.012*\"программный\" + 0.012*\"мс\" + 0.012*\"блокчейн\" + 0.011*\"драйвер\" + 0.011*\"директория\"'),\n",
              " (54,\n",
              "  '0.017*\"бд\" + 0.016*\"улучшение\" + 0.016*\"тело\" + 0.015*\"ия\" + 0.014*\"кластер\" + 0.013*\"ребята\" + 0.013*\"исследователь\" + 0.011*\"“”\" + 0.011*\"любить\" + 0.010*\"аргумент\"'),\n",
              " (70,\n",
              "  '0.176*\"координата\" + 0.068*\"сутки\" + 0.051*\"онлайн\" + 0.043*\"автомобиль\" + 0.030*\"хватить\" + 0.019*\"слушать\" + 0.019*\"стоять\" + 0.013*\"спутник\" + 0.013*\"блокировка\" + 0.013*\"мыть\"'),\n",
              " (69,\n",
              "  '0.018*\"реклама\" + 0.016*\"уязвимость\" + 0.014*\"днк\" + 0.014*\"байт\" + 0.013*\"территория\" + 0.013*\"рекомендация\" + 0.013*\"компиляция\" + 0.012*\"машинный\" + 0.011*\"исследователь\" + 0.011*\"рф\"'),\n",
              " (15,\n",
              "  '0.102*\"ия\" + 0.072*\"стадия\" + 0.059*\"информационный\" + 0.048*\"отрасль\" + 0.032*\"территория\" + 0.032*\"закон\" + 0.031*\"протяжение\" + 0.030*\"расход\" + 0.029*\"заключение\" + 0.028*\"поддерживаться\"'),\n",
              " (4,\n",
              "  '0.096*\"аппарат\" + 0.052*\"напряжение\" + 0.050*\"состав\" + 0.049*\"ом\" + 0.048*\"сверху\" + 0.048*\"собираться\" + 0.048*\"поколение\" + 0.045*\"автоматизация\" + 0.007*\"совет\" + 0.006*\"директория\"'),\n",
              " (47,\n",
              "  '0.104*\"ожидание\" + 0.096*\"ит\" + 0.056*\"заказчик\" + 0.051*\"обслуживание\" + 0.050*\"”\" + 0.031*\"восстановление\" + 0.023*\"робот\" + 0.020*\"отчёт\" + 0.020*\"потеря\" + 0.018*\"улучшение\"'),\n",
              " (58,\n",
              "  '0.022*\"директория\" + 0.020*\"резервный_копирование\" + 0.016*\"флаг\" + 0.015*\"миллиард\" + 0.015*\"командный\" + 0.013*\"покупка\" + 0.012*\"аналитика\" + 0.012*\"операционный\" + 0.012*\"потеря\" + 0.011*\"окружение\"'),\n",
              " (10,\n",
              "  '0.033*\"отчёт\" + 0.016*\"включение\" + 0.015*\"клетка\" + 0.014*\"курс\" + 0.013*\"рисунок\" + 0.013*\"вода\" + 0.011*\"проектирование\" + 0.011*\"градус\" + 0.011*\"исследователь\" + 0.010*\"цвета\"'),\n",
              " (86,\n",
              "  '0.013*\"ося\" + 0.012*\"ит\" + 0.011*\"спутник\" + 0.011*\"платёж\" + 0.010*\"акция\" + 0.010*\"полый\" + 0.010*\"кб\" + 0.010*\"шифрование\" + 0.009*\"рейтинг\" + 0.009*\"облачный\"'),\n",
              " (59,\n",
              "  '0.090*\"граница\" + 0.062*\"ребёнок\" + 0.041*\"исследователь\" + 0.036*\"рис\" + 0.035*\"лаборатория\" + 0.032*\"обнаружить\" + 0.031*\"голов\" + 0.031*\"зона\" + 0.030*\"выяснить\" + 0.026*\"преобразование\"'),\n",
              " (20,\n",
              "  '0.123*\"курс\" + 0.098*\"уязвимость\" + 0.084*\"отчёт\" + 0.033*\"субд\" + 0.026*\"презентация\" + 0.022*\"хостинг\" + 0.015*\"сюда\" + 0.014*\"обратиться\" + 0.013*\"январь\" + 0.013*\"выясниться\"'),\n",
              " (71,\n",
              "  '0.016*\"«я\" + 0.012*\"вперёд\" + 0.012*\"•\" + 0.012*\"индекс\" + 0.011*\"печать\" + 0.011*\"принтер\" + 0.011*\"вм\" + 0.010*\"загрузить\" + 0.010*\"шагом\" + 0.010*\"проектирование\"'),\n",
              " (30,\n",
              "  '0.165*\"бюджет\" + 0.037*\"исполнение\" + 0.034*\"эксплуатация\" + 0.025*\"отдел\" + 0.025*\"внутренний\" + 0.023*\"проведение\" + 0.018*\"движок\" + 0.017*\"январь\" + 0.017*\"сбор\" + 0.017*\"аналитика\"'),\n",
              " (74,\n",
              "  '0.052*\"социальный\" + 0.049*\"рис\" + 0.042*\"наушник\" + 0.030*\"инженер\" + 0.027*\"организовать\" + 0.026*\"сократить\" + 0.026*\"повышение\" + 0.026*\"уменьшить\" + 0.025*\"служба\" + 0.025*\"обладать\"'),\n",
              " (78,\n",
              "  '0.208*\"спецификация\" + 0.048*\"настоящее\" + 0.018*\"синтаксис\" + 0.018*\"объём\" + 0.018*\"флаг\" + 0.018*\"изучить\" + 0.018*\"развиваться\" + 0.018*\"предоставить\" + 0.017*\"медленно\" + 0.017*\"собираться\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RVsjI1smfiEF"
      },
      "source": [
        "Чтобы это проинтерпретировать, надо постараться.\n",
        "Можно притянуть за уши что-то такое:\n",
        "- подготовительная стадия (кто-то рзвивается, изучает синтаксис, собирается сменить сферу, делает что-то медленно):\n",
        "  '0.208*\"спецификация\" + 0.048*\"настоящее\" + 0.018*\"синтаксис\" + 0.018*\"объём\" + 0.018*\"флаг\" + 0.018*\"изучить\" + 0.018*\"развиваться\" + 0.018*\"предоставить\" + 0.017*\"медленно\" + 0.017*\"собираться\"')\n",
        "  - получение данных в ходе экспериментов (исследователь в лаборатории занимается какими-то преобразованиями и представляет результаты на рисунках)\n",
        "  - организация работы (бюджет, исполнения, эксплуатация, аналитика, январь - видимо, как срок сдачи отчётности)\n",
        "\n",
        "  После добавления tfidf выделяются подтемы внутри основной тематики текстов, а не прихватываются периферийные (боль, политика и т.п.)\n",
        "  Сами тематики лучше, чем без tfidf, но по-прежнему хуже, чем без нграм.\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5Pa5nS0mNny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yr7WbkXjIhn",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzDP6psojJ4B",
        "colab_type": "text"
      },
      "source": [
        "Воспользуемся NFM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IDZTWPKjg-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e48yTI5klKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stexts = [' '.join(text) for text in texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58pCfRCjkpEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1000, min_df=10, max_df=0.3, ngram_range=(1,3))\n",
        "X = vectorizer.fit_transform(stexts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Nd7ZSgkxHj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "3f37d1ff-7118-4b68-ab5e-1d41335fca03"
      },
      "source": [
        "import math\n",
        "min_err = math.inf\n",
        "for n in [15, 30, 45]:\n",
        "  for a in [0, 1, 2]:\n",
        "    model = NMF(n_components=30, alpha=a)  \n",
        "    model.fit(X)\n",
        "    err = model.reconstruction_err_\n",
        "    print('err:', err, 'params:', [n, a])\n",
        "    if err < min_err:\n",
        "      min_err = err\n",
        "      best_model = model\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "err: 54.519443316939274 params: [15, 0]\n",
            "err: 54.80389249524452 params: [15, 1]\n",
            "err: 55.5789250163123 params: [15, 2]\n",
            "err: 54.51074161526118 params: [30, 0]\n",
            "err: 54.77937362336289 params: [30, 1]\n",
            "err: 55.578926043744595 params: [30, 2]\n",
            "err: 54.52897392816625 params: [45, 0]\n",
            "err: 54.77441694610429 params: [45, 1]\n",
            "err: 55.57700716896436 params: [45, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbqkgE66mReq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "5b9b60a8-878a-48d5-d67a-3cefdb3aa911"
      },
      "source": [
        "feat_names = vectorizer.get_feature_names()\n",
        "top_words = best_model.components_.argsort()[:,:-5:-1]\n",
        "\n",
        "for i in range(top_words.shape[0]):\n",
        "    words = [feat_names[j] for j in top_words[i]]\n",
        "    print(i, \"  \".join(words))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 какой то  ещё  жизнь  вообще\n",
            "1 игра  игрок  игровой  играть\n",
            "2 файл  папка  строка  скрипт\n",
            "3 сервер  настройка  сервис  конфигурация\n",
            "4 устройство  смартфон  мобильный  устройство который\n",
            "5 объект  класс  метод  значение\n",
            "6 язык  программирование  язык программирование  программист\n",
            "7 сайт  страница  браузер  реклама\n",
            "8 память  процессор  гб  диск\n",
            "9 продукт  сервис  технология  платформа\n",
            "10 блок  переменный  длина  кнопка\n",
            "11 мозг  исследование  учёный  группа\n",
            "12 элемент  компонент  значение  свойство\n",
            "13 тест  тестирование  библиотека  ошибка\n",
            "14 сеть  трафик  связь  интернет\n",
            "15 запрос  таблица  строка  ответ\n",
            "16 энергия  земля  вселенная  поверхность\n",
            "17 сообщение  бот  сервис  канал\n",
            "18 клиент  услуга  сотрудник  бизнес\n",
            "19 модель  обучение  ия  изображение\n",
            "20 машина  виртуальный  виртуальный машина  вм\n",
            "21 модуль  пакет  компонент  поддержка\n",
            "22 сигнал  звук  частота  значение\n",
            "23 книга  часы  друг  читать\n",
            "24 камера  видео  смартфон  карта\n",
            "25 программа  компьютер  программный  программный обеспечение\n",
            "26 ключ  пароль  алгоритм  значение\n",
            "27 рубль  цена  товар  рынок\n",
            "28 безопасность  уязвимость  атака  защита\n",
            "29 база  база дать  запись  таблица\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_HdPRiGo4xi",
        "colab_type": "text"
      },
      "source": [
        "Группы хорошо интерпретируются:\n",
        "- работа с базами данных (запрос  таблица  строка  ответ)\n",
        "- организация бизнеса (клиент услуга сотрудник бизнес)\n",
        "- обработка звука (сигнал звук частота значение)\n",
        "Но некоторые классы представлены однокоренными словами (игра игрок игровой играть), а некоторые дублируются\n",
        "Возможно, при переборе моделей стоит извлекать слова в каждом результате, выявлять такие случаи и не записывать в best model варианты с дублями/пробовать уменьшать количество тем при тех же остальных параметрах. Как ни странно, от количества тем метрика ошибки почти не зависела"
      ]
    }
  ]
}